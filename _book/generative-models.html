<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Generative models | Moritz’ Machine Learning Summary</title>
  <meta name="description" content="<p>This is a minimal example of using the bookdown package to write a book.
set in the _output.yml file.
The HTML output format for this example is bookdown::gitbook,</p>" />
  <meta name="generator" content="bookdown 0.31 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Generative models | Moritz’ Machine Learning Summary" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="<p>This is a minimal example of using the bookdown package to write a book.
set in the _output.yml file.
The HTML output format for this example is bookdown::gitbook,</p>" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Generative models | Moritz’ Machine Learning Summary" />
  
  <meta name="twitter:description" content="<p>This is a minimal example of using the bookdown package to write a book.
set in the _output.yml file.
The HTML output format for this example is bookdown::gitbook,</p>" />
  

<meta name="author" content="Moritz Gück" />


<meta name="date" content="2023-02-12" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="unsupervised-learning.html"/>
<link rel="next" href="regression.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Summary</a></li>
<li class="chapter" data-level="1" data-path="probability-theory-linear-algebra.html"><a href="probability-theory-linear-algebra.html"><i class="fa fa-check"></i><b>1</b> Probability Theory &amp; Linear Algebra</a>
<ul>
<li class="chapter" data-level="1.1" data-path="probability-theory-linear-algebra.html"><a href="probability-theory-linear-algebra.html#probability-theory"><i class="fa fa-check"></i><b>1.1</b> Probability Theory</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="probability-theory-linear-algebra.html"><a href="probability-theory-linear-algebra.html#probability-basics"><i class="fa fa-check"></i><b>1.1.1</b> Probability Basics</a></li>
<li class="chapter" data-level="1.1.2" data-path="probability-theory-linear-algebra.html"><a href="probability-theory-linear-algebra.html#probability-distributions"><i class="fa fa-check"></i><b>1.1.2</b> Probability distributions</a></li>
<li class="chapter" data-level="1.1.3" data-path="probability-theory-linear-algebra.html"><a href="probability-theory-linear-algebra.html#CLT"><i class="fa fa-check"></i><b>1.1.3</b> Central limit theorem</a></li>
<li class="chapter" data-level="1.1.4" data-path="probability-theory-linear-algebra.html"><a href="probability-theory-linear-algebra.html#bayesian-probability"><i class="fa fa-check"></i><b>1.1.4</b> Bayesian probability</a></li>
<li class="chapter" data-level="1.1.5" data-path="probability-theory-linear-algebra.html"><a href="probability-theory-linear-algebra.html#further-concepts"><i class="fa fa-check"></i><b>1.1.5</b> Further Concepts</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="probability-theory-linear-algebra.html"><a href="probability-theory-linear-algebra.html#linear-algebra"><i class="fa fa-check"></i><b>1.2</b> Linear Algebra</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="probability-theory-linear-algebra.html"><a href="probability-theory-linear-algebra.html#vectors"><i class="fa fa-check"></i><b>1.2.1</b> Vectors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="data-basics.html"><a href="data-basics.html"><i class="fa fa-check"></i><b>2</b> Data Basics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="data-basics.html"><a href="data-basics.html#similarity-and-distance-measures"><i class="fa fa-check"></i><b>2.1</b> Similarity and Distance Measures</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="data-basics.html"><a href="data-basics.html#metrics"><i class="fa fa-check"></i><b>2.1.1</b> Metrics</a></li>
<li class="chapter" data-level="2.1.2" data-path="data-basics.html"><a href="data-basics.html#similarity-measures-on-vectors"><i class="fa fa-check"></i><b>2.1.2</b> Similarity measures on vectors</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="data-basics.html"><a href="data-basics.html#preprocessing-data"><i class="fa fa-check"></i><b>2.2</b> Preprocessing data</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="data-basics.html"><a href="data-basics.html#standardization"><i class="fa fa-check"></i><b>2.2.1</b> Standardization</a></li>
<li class="chapter" data-level="2.2.2" data-path="data-basics.html"><a href="data-basics.html#encoding-categorical-features"><i class="fa fa-check"></i><b>2.2.2</b> Encoding categorical features</a></li>
<li class="chapter" data-level="2.2.3" data-path="data-basics.html"><a href="data-basics.html#imputing-missing-values"><i class="fa fa-check"></i><b>2.2.3</b> Imputing missing values</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="data-basics.html"><a href="data-basics.html#splitting-in-training--and-test-data"><i class="fa fa-check"></i><b>2.3</b> Splitting in training- and test-data</a></li>
<li class="chapter" data-level="2.4" data-path="data-basics.html"><a href="data-basics.html#feature-selection"><i class="fa fa-check"></i><b>2.4</b> Feature selection</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="data-basics.html"><a href="data-basics.html#a-priori-feature-selection"><i class="fa fa-check"></i><b>2.4.1</b> A priori feature selection</a></li>
<li class="chapter" data-level="2.4.2" data-path="data-basics.html"><a href="data-basics.html#wrapper-methods"><i class="fa fa-check"></i><b>2.4.2</b> wrapper methods</a></li>
<li class="chapter" data-level="2.4.3" data-path="data-basics.html"><a href="data-basics.html#advice-pitfalls"><i class="fa fa-check"></i><b>2.4.3</b> Advice &amp; Pitfalls</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="data-basics.html"><a href="data-basics.html#hyper-parameter-tuning"><i class="fa fa-check"></i><b>2.5</b> Hyper-parameter tuning</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="data-basics.html"><a href="data-basics.html#grid-search"><i class="fa fa-check"></i><b>2.5.1</b> Grid search</a></li>
<li class="chapter" data-level="2.5.2" data-path="data-basics.html"><a href="data-basics.html#randomized-search"><i class="fa fa-check"></i><b>2.5.2</b> randomized search</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="data-basics.html"><a href="data-basics.html#model-selection"><i class="fa fa-check"></i><b>2.6</b> Model selection</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="data-basics.html"><a href="data-basics.html#crossval"><i class="fa fa-check"></i><b>2.6.1</b> Cross Validation</a></li>
<li class="chapter" data-level="2.6.2" data-path="data-basics.html"><a href="data-basics.html#bootstrapping"><i class="fa fa-check"></i><b>2.6.2</b> Bootstrapping</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="data-basics.html"><a href="data-basics.html#errors-in-machine-learning"><i class="fa fa-check"></i><b>2.7</b> Errors in machine learning</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="data-basics.html"><a href="data-basics.html#bias-and-variance"><i class="fa fa-check"></i><b>2.7.1</b> Bias and Variance</a></li>
<li class="chapter" data-level="2.7.2" data-path="data-basics.html"><a href="data-basics.html#regularization"><i class="fa fa-check"></i><b>2.7.2</b> Regularization</a></li>
<li class="chapter" data-level="2.7.3" data-path="data-basics.html"><a href="data-basics.html#bagging"><i class="fa fa-check"></i><b>2.7.3</b> Bagging</a></li>
<li class="chapter" data-level="2.7.4" data-path="data-basics.html"><a href="data-basics.html#boosting"><i class="fa fa-check"></i><b>2.7.4</b> Boosting</a></li>
<li class="chapter" data-level="2.7.5" data-path="data-basics.html"><a href="data-basics.html#stacking"><i class="fa fa-check"></i><b>2.7.5</b> Stacking</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="data-basics.html"><a href="data-basics.html#tips-for-machine-learning-projects"><i class="fa fa-check"></i><b>2.8</b> Tips for machine learning projects</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="data-basics.html"><a href="data-basics.html#general-advice"><i class="fa fa-check"></i><b>2.8.1</b> General advice</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="data-basics.html"><a href="data-basics.html#common-mistakes"><i class="fa fa-check"></i><b>2.9</b> Common mistakes</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="classification-methods.html"><a href="classification-methods.html"><i class="fa fa-check"></i><b>3</b> Classification Methods</a>
<ul>
<li class="chapter" data-level="3.1" data-path="classification-methods.html"><a href="classification-methods.html#evaluation-of-classifiers"><i class="fa fa-check"></i><b>3.1</b> Evaluation of Classifiers</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="classification-methods.html"><a href="classification-methods.html#confusion-matrix"><i class="fa fa-check"></i><b>3.1.1</b> Confusion matrix</a></li>
<li class="chapter" data-level="3.1.2" data-path="classification-methods.html"><a href="classification-methods.html#basic-quality-measures"><i class="fa fa-check"></i><b>3.1.2</b> Basic Quality Measures</a></li>
<li class="chapter" data-level="3.1.3" data-path="classification-methods.html"><a href="classification-methods.html#area-under-the-curve"><i class="fa fa-check"></i><b>3.1.3</b> Area under the Curve</a></li>
<li class="chapter" data-level="3.1.4" data-path="classification-methods.html"><a href="classification-methods.html#handling-unbalanced-data"><i class="fa fa-check"></i><b>3.1.4</b> Handling Unbalanced Data</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="classification-methods.html"><a href="classification-methods.html#classification-algorithms"><i class="fa fa-check"></i><b>3.2</b> Classification Algorithms</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="classification-methods.html"><a href="classification-methods.html#nearest-neighbors-classifier"><i class="fa fa-check"></i><b>3.2.1</b> Nearest Neighbors Classifier</a></li>
<li class="chapter" data-level="3.2.2" data-path="classification-methods.html"><a href="classification-methods.html#naive-bayes-classifier"><i class="fa fa-check"></i><b>3.2.2</b> Naive Bayes Classifier</a></li>
<li class="chapter" data-level="3.2.3" data-path="classification-methods.html"><a href="classification-methods.html#linear-discriminant-analysis-lda"><i class="fa fa-check"></i><b>3.2.3</b> Linear discriminant analysis (LDA)</a></li>
<li class="chapter" data-level="3.2.4" data-path="classification-methods.html"><a href="classification-methods.html#support-vector-classifier-svc"><i class="fa fa-check"></i><b>3.2.4</b> Support Vector Classifier (SVC)</a></li>
<li class="chapter" data-level="3.2.5" data-path="classification-methods.html"><a href="classification-methods.html#decision-trees"><i class="fa fa-check"></i><b>3.2.5</b> Decision Trees</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html"><i class="fa fa-check"></i><b>4</b> Unsupervised Learning</a>
<ul>
<li class="chapter" data-level="4.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#custering-methods"><i class="fa fa-check"></i><b>4.1</b> Custering Methods</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#metrics-for-clustering-algorithms"><i class="fa fa-check"></i><b>4.1.1</b> metrics for Clustering algorithms</a></li>
<li class="chapter" data-level="4.1.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#k-means-clustering"><i class="fa fa-check"></i><b>4.1.2</b> K-Means Clustering</a></li>
<li class="chapter" data-level="4.1.3" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#graph-based-clustering"><i class="fa fa-check"></i><b>4.1.3</b> Graph-Based Clustering</a></li>
<li class="chapter" data-level="4.1.4" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#spectral-clustering"><i class="fa fa-check"></i><b>4.1.4</b> Spectral Clustering</a></li>
<li class="chapter" data-level="4.1.5" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#SSP"><i class="fa fa-check"></i><b>4.1.5</b> Sparse Subspace Clustering (SSP)</a></li>
<li class="chapter" data-level="4.1.6" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#soft-assignment-clustering"><i class="fa fa-check"></i><b>4.1.6</b> Soft-assignment Clustering</a></li>
<li class="chapter" data-level="4.1.7" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#artificial-neural-networks-for-clustering"><i class="fa fa-check"></i><b>4.1.7</b> Artificial Neural Networks for Clustering</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#mapping-to-lower-dimensions"><i class="fa fa-check"></i><b>4.2</b> Mapping to lower dimensions</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#manifold-learning"><i class="fa fa-check"></i><b>4.2.1</b> Manifold learning</a></li>
<li class="chapter" data-level="4.2.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#decomposition-techniques"><i class="fa fa-check"></i><b>4.2.2</b> Decomposition techniques</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#outlier-detection"><i class="fa fa-check"></i><b>4.3</b> Outlier detection</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#local-outlier-factor"><i class="fa fa-check"></i><b>4.3.1</b> Local outlier factor</a></li>
<li class="chapter" data-level="4.3.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#isolation-forest"><i class="fa fa-check"></i><b>4.3.2</b> Isolation forest</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="generative-models.html"><a href="generative-models.html"><i class="fa fa-check"></i><b>5</b> Generative models</a>
<ul>
<li class="chapter" data-level="5.1" data-path="generative-models.html"><a href="generative-models.html#generative-models-for-discrete-data"><i class="fa fa-check"></i><b>5.1</b> Generative Models for Discrete Data</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="generative-models.html"><a href="generative-models.html#bayesian-concept-learning"><i class="fa fa-check"></i><b>5.1.1</b> Bayesian Concept Learning</a></li>
<li class="chapter" data-level="5.1.2" data-path="generative-models.html"><a href="generative-models.html#beta-binomial-model"><i class="fa fa-check"></i><b>5.1.2</b> Beta-binomial model</a></li>
<li class="chapter" data-level="5.1.3" data-path="generative-models.html"><a href="generative-models.html#dirichlet-multinomial-model"><i class="fa fa-check"></i><b>5.1.3</b> Dirichlet-multinomial model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>6</b> Regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="regression.html"><a href="regression.html#evaluation-of-regression-models"><i class="fa fa-check"></i><b>6.1</b> Evaluation of regression models</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="regression.html"><a href="regression.html#r2-score"><i class="fa fa-check"></i><b>6.1.1</b> R^2 score</a></li>
<li class="chapter" data-level="6.1.2" data-path="regression.html"><a href="regression.html#mean-squared-error"><i class="fa fa-check"></i><b>6.1.2</b> Mean squared error</a></li>
<li class="chapter" data-level="6.1.3" data-path="regression.html"><a href="regression.html#visual-tools"><i class="fa fa-check"></i><b>6.1.3</b> Visual tools</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="regression.html"><a href="regression.html#linear-models"><i class="fa fa-check"></i><b>6.2</b> Linear Models</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="regression.html"><a href="regression.html#ordinary-least-squares"><i class="fa fa-check"></i><b>6.2.1</b> Ordinary Least Squares</a></li>
<li class="chapter" data-level="6.2.2" data-path="regression.html"><a href="regression.html#lasso-regression"><i class="fa fa-check"></i><b>6.2.2</b> Lasso regression</a></li>
<li class="chapter" data-level="6.2.3" data-path="regression.html"><a href="regression.html#ridge-regression"><i class="fa fa-check"></i><b>6.2.3</b> Ridge regression</a></li>
<li class="chapter" data-level="6.2.4" data-path="regression.html"><a href="regression.html#bayesian-regression"><i class="fa fa-check"></i><b>6.2.4</b> Bayesian regression</a></li>
<li class="chapter" data-level="6.2.5" data-path="regression.html"><a href="regression.html#generalized-linear-models"><i class="fa fa-check"></i><b>6.2.5</b> Generalized linear models</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="regression.html"><a href="regression.html#gaussian-process-regression"><i class="fa fa-check"></i><b>6.3</b> Gaussian process regression</a></li>
<li class="chapter" data-level="6.4" data-path="regression.html"><a href="regression.html#gradient-boosted-tree-regression"><i class="fa fa-check"></i><b>6.4</b> Gradient boosted tree regression</a></li>
<li class="chapter" data-level="6.5" data-path="regression.html"><a href="regression.html#time-series-forecasting"><i class="fa fa-check"></i><b>6.5</b> Time Series Forecasting</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="regression.html"><a href="regression.html#arimax-model"><i class="fa fa-check"></i><b>6.5.1</b> ARIMA(X) Model</a></li>
<li class="chapter" data-level="6.5.2" data-path="regression.html"><a href="regression.html#varmmax-model"><i class="fa fa-check"></i><b>6.5.2</b> VARMMA(X) Model</a></li>
<li class="chapter" data-level="6.5.3" data-path="regression.html"><a href="regression.html#prophet-model"><i class="fa fa-check"></i><b>6.5.3</b> Prophet-Model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="neural-networks-neural-networks.html"><a href="neural-networks-neural-networks.html"><i class="fa fa-check"></i><b>7</b> Neural Networks {#Neural Networks}</a>
<ul>
<li class="chapter" data-level="7.1" data-path="neural-networks-neural-networks.html"><a href="neural-networks-neural-networks.html#introduction"><i class="fa fa-check"></i><b>7.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="neural-networks-neural-networks.html"><a href="neural-networks-neural-networks.html#non-linearities"><i class="fa fa-check"></i><b>7.1.1</b> Non-Linearities</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="neural-networks-neural-networks.html"><a href="neural-networks-neural-networks.html#feedforward-neural-network-multi-layer-perceptron"><i class="fa fa-check"></i><b>7.2</b> Feedforward Neural Network / Multi-Layer Perceptron</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="neural-networks-neural-networks.html"><a href="neural-networks-neural-networks.html#backpropagation"><i class="fa fa-check"></i><b>7.2.1</b> Backpropagation</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="neural-networks-neural-networks.html"><a href="neural-networks-neural-networks.html#convolutional-neural-networks"><i class="fa fa-check"></i><b>7.3</b> Convolutional Neural Networks</a></li>
<li class="chapter" data-level="7.4" data-path="neural-networks-neural-networks.html"><a href="neural-networks-neural-networks.html#autoencoders"><i class="fa fa-check"></i><b>7.4</b> Autoencoders</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="neural-networks-neural-networks.html"><a href="neural-networks-neural-networks.html#autoencoders-for-clustering"><i class="fa fa-check"></i><b>7.4.1</b> Autoencoders for clustering</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="neural-networks-neural-networks.html"><a href="neural-networks-neural-networks.html#generative-adversarial-networks"><i class="fa fa-check"></i><b>7.5</b> Generative adversarial networks</a></li>
<li class="chapter" data-level="7.6" data-path="neural-networks-neural-networks.html"><a href="neural-networks-neural-networks.html#recurrent-neural-networks"><i class="fa fa-check"></i><b>7.6</b> Recurrent neural networks</a></li>
<li class="chapter" data-level="7.7" data-path="neural-networks-neural-networks.html"><a href="neural-networks-neural-networks.html#long-short-term-memory-networks"><i class="fa fa-check"></i><b>7.7</b> Long short-term memory networks</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="explanation-and-inspection-methods.html"><a href="explanation-and-inspection-methods.html"><i class="fa fa-check"></i><b>8</b> Explanation and inspection methods</a>
<ul>
<li class="chapter" data-level="8.1" data-path="explanation-and-inspection-methods.html"><a href="explanation-and-inspection-methods.html#global-explainability-methods"><i class="fa fa-check"></i><b>8.1</b> Global explainability methods</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="explanation-and-inspection-methods.html"><a href="explanation-and-inspection-methods.html#inherently-explainable-algorithms"><i class="fa fa-check"></i><b>8.1.1</b> Inherently explainable algorithms</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="explanation-and-inspection-methods.html"><a href="explanation-and-inspection-methods.html#local-explainability-methods"><i class="fa fa-check"></i><b>8.2</b> Local explainability methods</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="explanation-and-inspection-methods.html"><a href="explanation-and-inspection-methods.html#shapely-method"><i class="fa fa-check"></i><b>8.2.1</b> Shapely method</a></li>
<li class="chapter" data-level="8.2.2" data-path="explanation-and-inspection-methods.html"><a href="explanation-and-inspection-methods.html#lime"><i class="fa fa-check"></i><b>8.2.2</b> LIME</a></li>
<li class="chapter" data-level="8.2.3" data-path="explanation-and-inspection-methods.html"><a href="explanation-and-inspection-methods.html#anchor-methods"><i class="fa fa-check"></i><b>8.2.3</b> Anchor methods</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Moritz’ Machine Learning Summary</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="generative-models" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Chapter 5</span> Generative models<a href="generative-models.html#generative-models" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="generative-models-for-discrete-data" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Generative Models for Discrete Data<a href="generative-models.html#generative-models-for-discrete-data" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="bayesian-concept-learning" class="section level3 hasAnchor" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Bayesian Concept Learning<a href="generative-models.html#bayesian-concept-learning" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>can learn a concept <span class="math inline">\(c \in C\)</span> from positive examples alone. For that
define the posterior: <span class="math inline">\(p(c|\mathcal{D})\)</span>. To get to learn a concept you
need a hypothesis space <span class="math inline">\(\mathcal{H}\)</span> and a version space (a subset of
<span class="math inline">\(\mathcal{H}\)</span>) that is consistent with <span class="math inline">\(\mathcal{D}\)</span>. You choose a
hypothesis <span class="math inline">\(h\)</span> by assuming that samples are randomly chosen from the
true concept and calculate
<span class="math inline">\(p(\mathcal{D}|h)=\lbrack \frac{1}{|h|}\rbrack^N\)</span> (sampling the <span class="math inline">\(N\)</span> data
points from <span class="math inline">\(h\)</span>). You than choose the hypothesis that has the highest
probability (thereby you choose suspicious coincidences of too broad
models). The priors can be chosen e.g. by giving lower priority to
concepts with complex rules (e.g. “all powers of 2 below 100 but not
64.”). This is subjective, however often beneficial for rapid learning.<br />
Using Bayes rule, we can calculate the posterior:
<span class="math display">\[p(h|\mathcal{D}) =\dfrac{p(\mathcal{D}|h)p(h)}{p(\mathcal{D})} =  \dfrac{p(\mathcal{D}|h)p(h)}{\sum_{h&#39; \in \mathcal{H}}p(\mathcal{D}|h&#39;)p(h&#39;)}=\dfrac{\mathbb{I}(\mathcal{D} \in h)p(h)}{\sum_{h&#39; \in \mathcal{H}}\mathbb{I}(\mathcal{D} \in h&#39;)p(h&#39;)},\]</span>
where <span class="math inline">\(\mathbb{I}(\mathcal{D} \in h)p(h)\)</span> = 1 if the data adhere to the
<span class="math inline">\(h\)</span>. The maximum of <span class="math inline">\(p(h|\mathcal{D})\)</span> is the <strong>MAP estimate</strong>.</p>
<p>With more data the MAP-estimate converges to the MLE. If the true
hypothesis is in <span class="math inline">\(\mathcal{H}\)</span> then MLE and MAP will converge to it
(<span class="math inline">\(\rightarrow\)</span> consistent estimators). If you take the entire
distribution of the hypotheses you get a distribution for the estimate
(and not a point prediction) <span class="math inline">\(\rightarrow\)</span> <strong>posterior predictive
distribution</strong>.
<span class="math display">\[p(\tilde{x}|\mathcal{D}) = \sum_h p(\tilde{x}|h)p(h|\mathcal{D})\]</span>
This weighting of hypotheses is called <strong>Bayes model averaging</strong>. For
small data sets you get a vague posterior and broad predictive
distribution. You can replace the posteriors with their delta-function:
<span class="math display">\[p(\tilde{x}|\mathcal{D}) = \sum_h p(\tilde{x}|h)\delta_{\hat{h}_{\text{MAP}}}(h)\]</span>
<span class="math inline">\(\rightarrow\)</span> <strong>plug-in approximation</strong> (under-represents uncertainty).</p>
</div>
<div id="beta-binomial-model" class="section level3 hasAnchor" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Beta-binomial model<a href="generative-models.html#beta-binomial-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>This is a distribution that uses a binomial distribution as its
likelihood and a beta-distribution over it’s <span class="math inline">\(\theta\)</span> parameter as its
prior.</p>
<div id="likelihood" class="section level4 hasAnchor" number="5.1.2.1">
<h4><span class="header-section-number">5.1.2.1</span> Likelihood<a href="generative-models.html#likelihood" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><span class="math display">\[p(\mathcal{D}|\theta) = \text{Bin}(k|n, \theta) \propto \theta^k (1-\theta)^{n-k},\]</span>
where <span class="math inline">\(k\)</span> are the successful trials, <span class="math inline">\(n\)</span> are the total trials and
<span class="math inline">\(\theta\)</span> are the success-probabilities of the single experiments. <span class="math inline">\(k\)</span>
and <span class="math inline">\(n-k\)</span> are <em>sufficient statistics of the data</em>:
<span class="math inline">\(p(\theta|\mathcal{D} = p(\theta|k, n-k))\)</span>.</p>
</div>
<div id="prior" class="section level4 hasAnchor" number="5.1.2.2">
<h4><span class="header-section-number">5.1.2.2</span> Prior<a href="generative-models.html#prior" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><span class="math display">\[\text{Beta}(\theta|\alpha, \beta) \propto \theta^{\alpha-1}(1-\theta)^{\beta-1}\]</span>
the parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are used as hyper parameters. The
prior has the same form as the likelihood <span class="math inline">\(\rightarrow\)</span> <em>conjugate
prior</em>.</p>
</div>
<div id="posterior" class="section level4 hasAnchor" number="5.1.2.3">
<h4><span class="header-section-number">5.1.2.3</span> Posterior<a href="generative-models.html#posterior" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><span class="math display">\[p(\theta|\mathcal{D}) \propto \text{Bin}(k|n,\theta)\text{Beta}(\theta|\alpha, \beta)=\text{Beta}(\theta|k+\alpha,n-k+\beta)\]</span>
We add pseudo-counts (<span class="math inline">\(\alpha, \beta\)</span>) to empirical counts (<span class="math inline">\(N, k\)</span>). The
posterior predictive distribution is: <span class="math display">\[\begin{aligned}
                p(\tilde{x}=1|\mathcal{D})&amp; =\int_0^1 p(\tilde{x}=1|\theta)p(\theta|\mathcal{D})\mathrm{d}\theta
                        =\int_0^1 \theta\text{Beta}(\theta|N-k+\alpha,k+\beta)\mathrm{d}\theta \\
                        &amp; =\text{E}[\theta|\mathcal{D}]=\dfrac{N-k+\alpha}{N\cancel{-k+k}+\alpha+\beta} \\
            \end{aligned}\]</span> If instead we used the MLE for <span class="math inline">\(\theta\)</span>
instead (<span class="math inline">\(p(\theta|\mathcal{D}) = p(\theta|\theta_{\text{MLE}})\)</span>) and we
only had little data and no failures (e.g. 3 coin flips and all are
tails). Then the MLE estimate would be <span class="math inline">\(\theta_{\text{MLE}}) = 0/3 = 0\)</span>.
This is called <em>zero count estimate</em> problem or <em>black swan paradox</em>
(i.e. you don’t attribute possibilities to something you have never seen
before). Solution: You use a uniform prior (<span class="math inline">\(\alpha = \beta = 1\)</span>):
<span class="math inline">\(p(\tilde{x}=1|\mathcal{D}) = \dfrac{N-k+1}{N+2}\)</span>.</p>
</div>
</div>
<div id="dirichlet-multinomial-model" class="section level3 hasAnchor" number="5.1.3">
<h3><span class="header-section-number">5.1.3</span> Dirichlet-multinomial model<a href="generative-models.html#dirichlet-multinomial-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Before: model of <span class="math inline">\(k\)</span> , now: <span class="math inline">\(k\)</span> times a (e.g. four pips on a die roll)
in <span class="math inline">\(n\)</span> experiments.</p>
<div id="prior-1" class="section level4 hasAnchor" number="5.1.3.1">
<h4><span class="header-section-number">5.1.3.1</span> Prior:<a href="generative-models.html#prior-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The Dirichlet distribution:
<span class="math display">\[\text{Dir}(\theta|\alpha) = \dfrac{1}{B({\alpha})}\prod\limits_{k=1}^K \theta_k^{\alpha_k-1}\]</span></p>
</div>
<div id="posterior-1" class="section level4 hasAnchor" number="5.1.3.2">
<h4><span class="header-section-number">5.1.3.2</span> Posterior:<a href="generative-models.html#posterior-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><span class="math display">\[\begin{aligned}
            p({\theta}|\mathcal{D})&amp; \propto p(\mathcal{D}|{\theta})p({\theta|\alpha}) \\
                &amp; \propto \prod\limits_{k=1}^K\theta_k^{N_k}\theta_k^{\alpha_k-1} = \prod\limits_{k=1}^K\theta_k^{N_k+\alpha_k-1}\\
                &amp; =\text{Dir}({\theta}|\alpha_1+N_1,\cdots,\alpha_K+N_K)
            \end{aligned}\]</span> The posterior predictive distribution is:
<span class="math display">\[\begin{aligned}
                p(\tilde{\tilde{X}}=j|\mathcal{D})&amp; =\int p(\tilde{X}=j|{\theta})p({\theta}|\mathcal{D})\mathrm{d}{\theta} \\
                    &amp; =\int p(\tilde{X}=j|\theta_j)\left[\int p({\theta}_{-j}, \theta_j|\mathcal{D})\mathrm{d}{\theta}_{-j}\right]\mathrm{d}\theta_j \\
                    &amp; =\int \theta_jp(\theta_j|\mathcal{D})\mathrm{d}\theta_j=\text{E}[\theta_j|\mathcal{D}]=\dfrac{N_j+\alpha_j}{\sum_k N_k+\alpha_k}
                \end{aligned}\]</span> (Again, we avoid the the zero-count
problem via the pseudo counts.)</p>
<!--# TODO: Write examples for sklearn or other library -->

</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="unsupervised-learning.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/05-Generative.rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
