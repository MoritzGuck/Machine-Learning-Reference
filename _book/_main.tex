% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\newcommand{\btw}{\marginlabel{\hspace{1cm} \faSearch \begin{large} $\rightarrow$ \end{large} }}
\usepackage{fancyhdr}
\usepackage[T1]{fontenc}
\usepackage{ae} % CM-Zeichens"atze mit T1 encoding
\usepackage{makeidx}
\usepackage{graphicx, caption}
\usepackage{hyperref}       % hyperlinks
\usepackage{ifthen}
\usepackage{verbatim}
\usepackage{tocloft}
%\usepackage{english}
%\usepackage{showidx}
\usepackage{subfiles} % Best loaded last in the preamble
\usepackage[english]{babel}
\usepackage{blindtext}
\usepackage{geometry}
\geometry{lmargin=4cm, rmargin=2cm}
\usepackage{titlesec}
\usepackage{mathtools}
\usepackage[makeroom]{cancel}
\usepackage{commath}
\usepackage{xr}
\usepackage{zref}
\usepackage[all]{nowidow}
\widowpenalty10000
\clubpenalty10000

\usepackage{amssymb,amsmath,bm}
\DeclareMathOperator{\sign}{sign}
\newcommand{\onevect}{1 \mkern-6mu 1}

\usepackage{bbold}
\usepackage[most]{tcolorbox}
\usepackage{bbm}
\usepackage{threeparttable}
\usepackage{cancel}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{plainnat}
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Moritz' Machine Learning Summary},
  pdfauthor={Moritz Gück},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Moritz' Machine Learning Summary}
\author{Moritz Gück}
\date{2023-02-12}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{summary}{%
\chapter*{Summary}\label{summary}}
\addcontentsline{toc}{chapter}{Summary}

This is a reference for machine learning approaches and methods. The
topics range from basic statistics to complex machine learning models
and explanation methods. For each method and model, I have provided the
underlying formulas (objective functions, prediction functions, etc.) as
well as code snippets from the respective python libraries. I made this
reference to quickly look up things I have studied already. I published
it to give data scientists a catalog to find methods for their problem,
refresh their knowledge and give references for further reading. If you
find errors or unclear explanations in this text, please file an issue
under: \texttt{github.com/MoritzGuck/All\_of\_ML-under\_construction}

\hypertarget{probability-theory-linear-algebra}{%
\chapter{Probability Theory \& Linear Algebra}\label{probability-theory-linear-algebra}}

\hypertarget{probability-theory}{%
\section{Probability Theory}\label{probability-theory}}

A probability is a measure of how frequent or likely an event will take
place.

\hypertarget{probability-basics}{%
\subsection{Probability Basics}\label{probability-basics}}

\hypertarget{probability-interpretations}{%
\subsubsection{Probability interpretations}\label{probability-interpretations}}

\begin{itemize}
\item
  \textbf{Frequentist:} Fraction of positive samples, if we measured
  infinitely many samples.
\item
  \textbf{Objectivist:} Probabilities are due to inherent uncertainty
  properties. Probabilities are calculated by putting outcomes of
  interest into relation with all possible outcomes.
\item
  \textbf{Subjectivist:} An agent's \emph{rational} degree of belief (not
  external). The belief needs to be coherent (i.e.~if you make bets
  using your probabilities you should not be guaranteed lose money)
  and therefore need to follow the rules of probability.
\item
  \textbf{Bayesian:} (Building on subjectivism) A reasonable expectation /
  degree of belief based on the information available to the
  statistician / system. It allows to give certainties to events,
  where we don't have samples on (e.g.~disappearance of the south pole
  until 2030).
\end{itemize}

Also the frequentist view is not free of subjectivity since you need to
compare events on otherwise similar objects. Usually there are no
completely similar objects, so you need to define them.

\hypertarget{probability-space}{%
\subsubsection{Probability Space}\label{probability-space}}

The probability space is a triplet space containing a sample/outcome
space \(\Omega\) (containing all possible atomic events), a collection of
events \(S\) (containing a subset of \(\Omega\) to which we want to assign
probabilities) and the mapping \(P\) between \(\Omega\) and \(S\).

\hypertarget{axioms-of-probability}{%
\subsubsection{Axioms of Probability}\label{axioms-of-probability}}

The mapping \(P\) must fulfill the axioms of probability:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(P(a) \geq 0\)
\item
  \(P(\Omega) = 1\)
\item
  \(a,b \in S\) and \(a \cap b = \{\}\)
  \(\Rightarrow P(a \cup b) = P(a) + P(b)\)
\end{enumerate}

\(a\), \(b\) are events.

\hypertarget{random-variable-rv}{%
\subsubsection{Random Variable (RV)}\label{random-variable-rv}}

A RV is a \textbf{function} that maps points from the sample space \(\Omega\)
to some range (e.g.~Real numbers or booleans). They are characterized by
their distribution function. E.g. for a coin toss:
\[X(\omega) = \begin{cases} 
                0, \text{ if } \omega = heads\\
                1, \text{ if } \omega = tails.
            \end{cases}\]

\hypertarget{proposition}{%
\subsubsection{Proposition}\label{proposition}}

A Proposition is a conclusion of a statistical inference/prediction that
can be true or false (e.g.~a classification of a datapoint). More
formally: A disjunction of events where the logic model holds. An event
can be written as a \textbf{propositional logic model}:\\
\(A = true, B = false \Rightarrow a \land \neg b\). Propositions can be
continuous, discrete or boolean.

\hypertarget{probability-distributions}{%
\subsection{Probability distributions}\label{probability-distributions}}

Probability distributions assign probabilities to to all possible points
in \(\Omega\) (e.g.~\(P(Weather) = \langle 0.3, 0.4, 0.2, 0.1 \rangle\),
representing Rain, sunshine, clouds and snow). Joint probability
distributions give you a probability for each atomic event of the RVs
(e.g.~\(P(weather, accident)\) gives you a \(2\times 4\) matrix.)

\hypertarget{cumulative-distribution-function-cdf}{%
\subsubsection{Cumulative Distribution Function (CDF)}\label{cumulative-distribution-function-cdf}}

The CDF is defined as \(F_X(x) = P(X \leq x)\) (See figure
\protect\hyperlink{CDF}{\(CDF\)}).

\begin{figure}
\hypertarget{CDF}{%
\centering
\includegraphics[width=0.6\textwidth,height=\textheight]{./figures/Normal_Distribution_CDF.png}
\caption{Cumulative distribution function of a normal distribution for
different mean (\(\mu\)) and variance (\(\sigma\)). \emph{Source: \href{https://commons.wikimedia.org/wiki/File:Normal_Distribution_CDF.svg}{user
Inductiveload on
wikimedia.org}.}}\label{CDF}
}
\end{figure}

\hypertarget{probability-density-function-pdf}{%
\subsubsection{Probability Density Function (PDF)}\label{probability-density-function-pdf}}

For continuous functions the PDF is defined by
\[p(x) =  {d \over dx} p(X \leq x).\] The probability of x being in a
finite interval is \[P(a < X \leq b) = \int_a^b p(x) dx\] A PDF is shown
in the following figure.

\begin{figure}
\hypertarget{Boxplot}{%
\centering
\includegraphics[width=0.6\textwidth,height=\textheight]{./figures/Boxplot_vs_PDF.png}
\caption{Probability density function of a normal distribution with variance
(\(\sigma\)). In red a range from a Box-plot is shown with
\protect\hyperlink{dist_prop}{quartiles} (Q1, Q3) and interquartile range (IQR). For the
cutoffs (borders to darker blue regions) the IQR (on top) and \(\sigma\)
are chosen. Another common cutoff is the confidence interval with light
blue regions having a probability mass of \(2 * \alpha / 2\). \emph{Source:
\href{https://commons.wikimedia.org/wiki/File:Boxplot_vs_PDF.svg}{user Jhguch on
wikimedia.org}.}}\label{Boxplot}
}
\end{figure}

\hypertarget{dist_prop}{%
\subsubsection{Properties of Distributions}\label{dist_prop}}

\begin{itemize}
\item
  The \textbf{expected value} (\(E\)) or \textbf{mean} (\(\mu\)) is given by
  \(E[X] = \sum_{x \in X} x*p(x)\) for discrete RVs and
  \(E[X] = \int_X x*p(x) dx\) for continuous RVs.
\item
  The \textbf{variance} measures the spread of a distribution:
  \(var[X] = \sigma^2 = E[(X-\mu)^2] = E[X]^2 - \mu^2\).
\item
  The \textbf{standard deviation} is given by: \(\sqrt{var[X]} = \sigma\).
\item
  The \textbf{mode} is the value with the highest probability (or the point
  in the PDF with the highest value):
\item
  The \textbf{median} is the point at which all point less than the median
  and all points greater than the median have the same probability
  (\(0.5\)).
\item
  The \textbf{quantiles} (\(Q\)) divide the datapoints into sets of equal
  number. The \(Q_1\) qua\textbf{r}tile has 25\% of the values below it. The
  \textbf{interquartile range} (IQR) is a measure to show the variability
  in the data (how distant the points from the first and last quartile
  are)
\end{itemize}

\hypertarget{diracdelta}{%
\subsubsection{Dirac delta function}\label{diracdelta}}

The \textbf{dirac delta} is simply a function that is infinite at one point
and 0 everywhere else:
\[\delta(x)=\begin{cases} \infty , \; \text{ if } x = 0 \\0, \quad \text{if } x \neq 0 \end{cases} \qquad \text{and } \int_{-\infty}^{\infty} \delta(x) dx = 1\]
(Needed for distributions further on)

\hypertarget{uniform-distribution}{%
\subsubsection{Uniform distribution}\label{uniform-distribution}}

The uniform distribution has the same probability throughout a specific
interval:
\[\text{Unif}(a,b) = \frac{1}{b-a} 1 \mkern-6mu 1 (a < x \leq b) = \begin{cases} 
                \frac{1}{b-a}, \quad \text{if } x \in [ a,b ] \\
                0, \qquad \text{else}
            \end{cases}\] \(1 \mkern-6mu 1\) is a vector of ones.

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth,height=\textheight]{./figures/Uniform_Distribution.png}
\caption{Uniform distribution. \emph{Source: \href{https://commons.wikimedia.org/wiki/File:Uniform_Distribution_PDF_SVG.svg}{user IkamusumeFan on
wikimedia.org}.}}
\end{figure}

\hypertarget{discrete-distributions}{%
\subsubsection{Discrete distributions}\label{discrete-distributions}}

Used for random variables that have discrete states.

\hypertarget{binomial-distribution}{%
\paragraph{Binomial distribution}\label{binomial-distribution}}

Used for series of experiments with two outcomes (success or miss. e.g.
a series of coin flips).
\[X \sim \text{Bin}(n, \theta ), \quad \text{Bin}(k|n,\theta)={n \choose k} \theta^k (1-\theta)^{n-k} , \quad {n \choose k} = \frac{n!}{k!(n-k)!},\]
where \(n\) is the number of total experiments, \(k\) is the number of
successful experiments and \(\theta\) is the probability of success of an
experiment.

\begin{figure}
\centering
\includegraphics{./figures/Pascals_triangle_binomial_distribution.png}
\caption{Binomial distribution of balls in \href{https://en.wikipedia.org/wiki/Pascal\%27s_triangle}{Pascals
triangles} with
different numbers of layers (The top one has 0 layers). Example: For a
triangle with \(n=6\) layers, the probability that a ball lands in the
middle box \(k=3\) is \(20/64\). \emph{Source: \href{https://commons.wikimedia.org/wiki/File:Pascal\%27s_triangle;_binomial_distribution.svg}{user Watchduck on
wikimedia.org}}}
\end{figure}

\hypertarget{bernoulli-distribution}{%
\paragraph{Bernoulli distribution}\label{bernoulli-distribution}}

Is a special case of the binomial distribution with \(n=1\) (e.g.~one coin
toss).
\[X \sim \text{Ber}(\theta ), \quad \text{Ber}(x | \theta)=\theta^{1 \mkern-6mu 1 (x=1)} (1-\theta)^{1 \mkern-6mu 1(x=0)}= \begin{cases}
                    \theta, \qquad \text{if } x=1 \\
                    1 - \theta, \; \text{if } x=0
                \end{cases}\]

\hypertarget{multinomial-distribution}{%
\paragraph{Multinomial distribution}\label{multinomial-distribution}}

Used for experiments with k different outcomes (e.g.~dice rolls:
Probability of different counts of the different sides).
\[\text{Mu}(x|n,\theta) =  {n \choose x_1, ..., x_K}\prod_{i=1}^K\theta_j^{x_j} = \frac{n!}{x_1!, ..., x_k!}\prod_{i=1}^K\theta_j^{x_j},\]
where \(k\) is the number of outcomes, \(x_j\) is the number times that
outcome \(j\) happens. \(X = (X_1, ..., X_K)\) is the \emph{random vector}.

\hypertarget{multinoulli-distribution}{%
\paragraph{Multinoulli distribution}\label{multinoulli-distribution}}

Is a special case of the multinomial distribution with \(n=1\). The random
vector is then represented in \emph{dummy-} or \emph{one-hot-encoding} (e.g.
\((0,0,1,0,0,0)\) if outcome 3 takes place).
\[\text{Mu}(x|1,\theta) = \prod_{j=0}^K \theta_j^{1 \mkern-6mu 1(x_j=1)}\]

\hypertarget{empirical-distribution}{%
\paragraph{Empirical distribution}\label{empirical-distribution}}

The empirical distribution follows the empirical measurements strictly.
The CDF jumps by 1/n every time a sample is ``encountered'' (see figure).

\[\text{p}_{\text{emp}}(A) = \frac{1}{N} \sum_{i=1}^N \delta_{x_i}(A), \quad \delta_{x_i}=\begin{cases}1, \quad \text{if } x \in A \\0, \quad \text{if } x \notin A \end{cases},\]
w where \(x_1, ..., x_N\) is a data set with N points. The points can also
be weighted: \[p(x) =  \sum_{i=1}^N w_i \delta_{x_i}(x)\]

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth,height=\textheight]{./figures/Empirical_distribution_function.png}
\caption{Cumulative empirical distribution function (blue line) for samples
drawn from a standard normal distribution (green line). The values of
the drawn samples is shown as grey lines at the bottom. Source: \href{https://commons.wikimedia.org/wiki/File:Empirical_distribution_function.png}{user
nagualdesign on
wikimedia.org.}}
\end{figure}

\hypertarget{continuous-distributions}{%
\subsubsection{Continuous distributions}\label{continuous-distributions}}

Used for random variables that have continuous states.

\hypertarget{normalgaussian-distribution}{%
\paragraph{Normal/Gaussian distribution}\label{normalgaussian-distribution}}

Often chosen for random noise because it is simple and needs few
assumptions (see sect. \protect\hyperlink{CLT}{CLT}). The PDF is given by:

\[p(x|\mu\sigma^2)= \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left[-\frac{(x-\mu)^2}{2\sigma^2}\right],\]
where \(\mu\) is the mean and \(\sigma^2\) is the variance. The CDF is given
by:
\[\Phi(x) = \frac{1}{\sqrt{2\pi}}\int_{\infty}^xe^{\frac{-t^2}{2}dt}\]

\hypertarget{multivariate-normalgaussian-distribution}{%
\paragraph{Multivariate normal/Gaussian distribution}\label{multivariate-normalgaussian-distribution}}

For T datapoints with k dimensions (features). The pdf is:
\[p(x|\mu,\Sigma) = \dfrac{1}{\sqrt{(2\pi)^k|\Sigma|}}\exp\left[-\dfrac{1}{2}(x-\mu)^\top\Sigma^{-1}(x-\mu)\right],\]
where x now has multiple dimension (\(x_1, x_2, ..., x_k\)) and \(\Sigma\)
is the \(k \times k\) covariance matrix:
\(\Sigma = \text{E}[(X-\mu)(X-\mu)]\). The covariance between features is:
\(\text{Cov}[X_i, X_j] = \text{E}[(X_i-\mu_i)(X_j-\mu_j)]\)

\hypertarget{beta-distribution}{%
\paragraph{Beta distribution}\label{beta-distribution}}

defined for \(0 \leq x \leq 1\) (see figure \protect\hyperlink{Beta_distr}{Beta
distribution}). The pdf is:
\[f(x|\alpha, \beta) = \frac{1}{B(\alpha,\beta)}x^{\alpha-1}(1-x)^{\beta-1}\]
The \href{https://en.wikipedia.org/wiki/Beta_function}{beta function} \(B\) is
there to normalize and ensure that the total probability is 1 .

\begin{figure}
\centering
\includegraphics[width=0.6\textwidth,height=\textheight]{./figures/Beta_distribution_pdf.png}
\caption{Probability density function of a beta-distribution with different
parameter values. \emph{Source: \href{https://commons.wikimedia.org/wiki/File:Beta_distribution_pdf.png}{user MarkSweep on
wikimedia.org}.}}
\end{figure}

\hypertarget{dirichlet-distribution}{%
\paragraph{Dirichlet distribution}\label{dirichlet-distribution}}

The multivariate version of the Beta distribution. The PDF is:
\[\text{Dir}({x}|{\alpha}) \triangleq \dfrac{1}{B({\alpha})}\prod\limits_{i=1}^K x_i^{\alpha_i-1},\quad \sum_{i=1}^K x_i =1, \quad x_i \geq 0 \text{ }\forall i\]

\begin{figure}
\centering
\includegraphics[width=0.6\textwidth,height=\textheight]{./figures/Dirichlet_distributions.png}
\caption{Probability density function of a Dirichlet-distribution on a
2-simplex (triangle) with different parameter values. Clockwise from top
left: \(\alpha\) = (6,2,2), (3,7,5), (6,2,6), (2,3,4). \emph{Source: \href{https://commons.wikimedia.org/wiki/File:Dirichlet_distributions.png}{user ThG
on
wikimedia.org}.}}
\end{figure}

\hypertarget{marginal-distributions}{%
\paragraph{Marginal distributions}\label{marginal-distributions}}

Are the probability distributions of subsets of the original
distribution. Marginal distributions of normal distributions are also
normal distributions.

\begin{figure}
\centering
\includegraphics[width=0.6\textwidth,height=\textheight]{./figures/Multivariate_gaussian.png}
\caption{Data following a 2D-Gaussian distribution. Marginal distributions are
shown on the sides in blue and orange. \emph{Source: \href{https://commons.wikimedia.org/wiki/File:Multivariate_Gaussian_inequality_demonstration.svg}{user Auguel on
wikimedia.org}.}}
\end{figure}

\hypertarget{CLT}{%
\subsection{Central limit theorem}\label{CLT}}

In many cases the sum of random variables will follow a normal
distribution as n goes to infinity.

\hypertarget{bayesian-probability}{%
\subsection{Bayesian probability}\label{bayesian-probability}}

Baeysian probability represents the plausibility of a proposition based
on the available information (i.e.~the degree at which the information
supports the proposition). The use of this form of statistics is
especially useful if random variables cannot be assumed to be i.i.d.
(i.e.~When an event is not independent of the event before it (e.g.
drawing balls without laying them back into the urn)).

\hypertarget{conditionalposterior-probability}{%
\subsubsection{Conditional/Posterior Probability}\label{conditionalposterior-probability}}

Expresses the probability of one event (\(Y\)) under the condition that
another event (\(E\)) has occurred. (e.g.~\(C\) = ``gets cancer'', \(S\) = ``is a
smoker'' \(\rightarrow\) \(p(C|S)=0.2\), meaning: ``given the \emph{sole
information} that someone is a smoker, their probability of getting
cancer is 20\%.'')\\
\strut \\
The conditional probability can be calculated like follows. By defining
the joined probability like so: \[P(A \cap B) = P(A \mid B) P(B)\] you
solve for \(P(A \mid B)\):
\[P(A \mid B) = \frac{P(A \cap B)}{P(B)}=\frac{P(A, B)}{P(B)}=\alpha{P(A, B)},\]
where \(\alpha\) is used as a normalization constant. If you have hidden
variables (confounding factors) you need to sum them out like so:
\[P(Y|E=e)=\alpha P(Y,E=e)=\alpha\sum_h P(Y,E=e,H=h)\] where \(X\)
contains all variables, \(Y\) is called \emph{query variable}, \(E\) is called
\emph{evidence variable}, \(H=X-Y-E\) is called \emph{hidden variable} or
\emph{confounding factor}. You get the joint probabilities by summing out the
hidden variable.

\textbf{!} Usually \(p(A|B) \neq p(B|A)\)\\
\textbf{!} Priors are often forgotten: E.g. \(P(\text{"COVID-19"})\) is
confused with \(P(\text{"COVID-19"}|\text{"Person is getting tested"})\)
(because only people with symptoms go to the testing station).\\
\textbf{!} Base rate neglect: Under-representing the prior probability. E.g.
You have a test with a 5\% false positive rate and a incidence of disease
of 2\% in the population. If you are tested positive in a population
screening your probability of having the disease is only 29\%.\\
Conditional distributions of Gaussian distributions are Gaussian
distributions themselves.

\hypertarget{independence}{%
\subsubsection{Independence}\label{independence}}

For independent variables it holds: \(P(A|B)=P(A)\) or \(P(B|A)=P(B)\)

\hypertarget{conditional-independence}{%
\subsubsection{Conditional independence}\label{conditional-independence}}

Two events \(A\) and \(B\) are independent, given \(C\): \(P(A|B,C)=P(A|C)\).
\(A\) and \(B\) must not have any information on each other, given the
information on \(C\). E.g. for school children:
\(P(\text{"vocabulary"}|\text{"height"}, \text{"age"})= P(\text{"vocabulary"}|\text{"age"})\).

\hypertarget{bayes-rule}{%
\subsubsection{Bayes Rule}\label{bayes-rule}}

Bayes rule is a structured approach to update prior beliefs /
probabilities with new information (data). With the conditional
probability from before (\(P(A,B)=P(A|B)P(B)=P(B|A)P(A)\)) we get \textbf{Bayes
rule} by transforming the right-side equation
to:\[P(\text{hypothesis}|\text{evidence}) =\dfrac{P(\text{evidence}|\text{hypothesis})P(\text{hypothesis})}{P(\text{evidence})}\]
often used as:
\[P(\text{model}|\text{data}) =\dfrac{P(\text{data}|\text{model})P(\text{model})}{P(\text{data})}\]

\hypertarget{terminology}{%
\paragraph{Terminology:}\label{terminology}}

\begin{itemize}
\item
  \(P(\text{hypothesis}|\text{evidence})\) = Posterior (How probable
  hypothesis is after incorporating new evidence)
\item
  \(P(\text{evidence}|\text{hypothesis})\) = Likelihood (How probable
  the evidence is, if the hypothesis is true)
\item
  \(P(\text{hypothesis})\) = Prior (How probable hypothesis was before
  seeing evidence)
\item
  \(P(\text{evidence})\) = Marginal (How probable evidence is under all
  possible hypotheses)
\item
  \(\dfrac{P(\text{evidence}|\text{hypothesis})}{P(\text{evidence})}\) =
  Support \(B\) provides for \(A\)
\item
  \(P(\text{data}|\text{model})P(\text{model})\) = joint probability
  (\(P(A,B)\))
\end{itemize}

\hypertarget{example-for-bayes-rule-using-covid-19-diagnostics}{%
\paragraph{Example for Bayes Rule using COVID-19 Diagnostics}\label{example-for-bayes-rule-using-covid-19-diagnostics}}

\[P(\text{COVID-19}|\text{cough}) =\dfrac{P(\text{cough}|\text{COVID-19})P(\text{COVID-19})}{P(\text{cough})} = \frac{0.7*0.01}{0.1}=0.07\]
Estimating \(P(\text{COVID-19}|\text{cough})\) is difficult, because there
can be an outbreak and the number changes. However,
\(P(\text{cough}|\text{COVID-19})\) stays stable, \(P(\text{COVID-19})\) and
\(P(\text{cough})\) can be easily determined.

\hypertarget{further-concepts}{%
\subsection{Further Concepts}\label{further-concepts}}

\hypertarget{convergence-in-probability-of-random-variables}{%
\subsubsection{Convergence in Probability of Random Variables}\label{convergence-in-probability-of-random-variables}}

You expect your random variables (\(X_i\)) to converge to an expected
random variable \(X\). I.e. after looking at infinite samples, the
probability that your random variable \(X_n\) differs more than a
threshold \(\epsilon\) from your target \(X\) should be zero.
\[\lim_{n \rightarrow \infty} P(|X_n - X| > \epsilon) = 0\]

\hypertarget{bernoullis-theorem-weak-law-of-large-numbers}{%
\subsubsection{Bernoulli's Theorem / Weak Law of Large Numbers}\label{bernoullis-theorem-weak-law-of-large-numbers}}

\[\lim_{n \rightarrow \infty} P(|\frac{\sum_{i=1}^n X_i}{n} - \mu| > \epsilon) = 0,\]
where \(X_1,...,X_n\) are independent \& identically distributed (i.i.d.)
RVs. \(\Rightarrow\) With enough samples, the sample mean will approach
the true mean. The \textbf{strong law of large numbers} states that
\(|\frac{\sum_{i=1}^n X_i}{n} - \mu| < \epsilon\) for any \(\epsilon > 0\).

\hypertarget{linear-algebra}{%
\section{Linear Algebra}\label{linear-algebra}}

This section is meant to give an intuitive understanding of the
underlying mechanisms of many algorithms. It is mainly a summary of the
course from
\href{https://youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab}{3Blue1Brown}
and
\href{https://deepai.org/machine-learning-glossary-and-terms/vector}{deepai.org}.

For details on the calculations see wikipedia.org.

\hypertarget{vectors}{%
\subsection{Vectors}\label{vectors}}

There are two relevant perspectives for us:

\begin{itemize}
\item
  \textbf{Mathematical:} Generally quantities that cannot be expressed by
  single number. They are objects in a \emph{vector space}. Such objects
  can also be e.g.~functions.
\item
  \textbf{Programmatical / Data:} Vectors are ordered lists of numbers. You
  model each sample as such an ordered list of numbers and the numbers
  represent the feature-value of that feature.
\end{itemize}

Your vectors are organized in a \emph{coordinate system} and commonly rooted
in the \emph{origin} (point \([0,0]\).\\

\hypertarget{linear-combinations}{%
\subsubsection{Linear combinations}\label{linear-combinations}}

You create \emph{linear combinations} of vectors by adding their components
(entries in a coordinate). Th All points that you can reach by linear
combinations are called the \emph{span} of these vectors. If a vector lies in
the span of another vector, they are \emph{linearly dependent}.\\
You can \emph{scale} (stretch or squish) vectors multiply vectors by
\emph{scalars} (i.e.~numbers). A vector with length \(1\) is called \emph{unit
vector}. The unit vectors in each direction of the coordinate system are
its \emph{basis vectors}. The basis vectors stacked together form an
\emph{identity matrix}: a matrix with 1s on its diagonal. Since there are
only values on its diagonal it is also a \emph{diagonal matrix}.\\

\[
I = \begin{bmatrix}
1 \quad 0 \quad 0 \\
0 \quad 1 \quad 0 \\
0 \quad 0 \quad 1
\end{bmatrix}
\]

\hypertarget{linear-transformations}{%
\subsubsection{Linear transformations}\label{linear-transformations}}

\emph{Linear transformations} are functions that move points around in a
vector space, while preserving the linear relationships between the
points (straight lines stay straight, the origin stays the origin). They
include rotations and reflections. You can understand the calculation of
the linear transformation of a point as follows: You give the basis
vectors a new location. You scale the new location basis vectors with
the components of the respective dimension of the vector you want to
transform. You take the linear combination of the scaled, transformed
basis vectors:

\[\begin{bmatrix} a \quad b \\ c \quad d \end{bmatrix} 
\begin{bmatrix} x \\ y \end{bmatrix}
  = x \begin{bmatrix} a \\ c \end{bmatrix} + y \begin{bmatrix} b \\ d \end{bmatrix} = \begin{bmatrix} x a  + y b \\ x c + y d \end{bmatrix}
\]

likewise, you can view matrix vector multiplication as a transformation
of your space. Full explanation: \href{https://youtu.be/kYB8IZa5AuE}{youtube.com -
3Blue1Brown} Multiplying two matrices
represents the sequential combination of two linear transformations in
your vector space.

A \emph{transpose} \(A^T\) of a matrix \(A\) is achieved by mirroring the matrix
on its diagonal and therefore swapping its rows and columns. This
commonly makes sense when evaluating if elements of two matrices line up
in regard to their scale. You can also check if matrices are
\href{https://en.wikipedia.org/wiki/Orthogonal_matrix}{orthogonal}.

An \emph{orthogonal/orthonormal matrix} is a matrix for which holds
\(A^TA=AA^T=I\), where \(I\) is the identity matrix. The columns of
orthogonal matrices are linearly independent of each other.

An \emph{inverse matrix} \(A^{-1}\) of a matrix \(A\) is the matrix that would
yield no transformation at all, if multiplied with \(A\).

\hypertarget{determinants}{%
\subsubsection{Determinants}\label{determinants}}

\emph{Determinants} can be used to measure how much a linear combination
compresses or stretches the space. If a transformation inverts the
space, the determinant will be negative. If a determinant is 0 it means
that the transformation maps the space onto a lower dimension.

The dimensions that come out of a transformation/matrix are its \emph{rank}.
All possible outputs of your matrix (the span constructed by its
columns) is the \emph{column space}. All vectors that are mapped to 0 (onto
the origin) are the \emph{null space} or \emph{kernel} of the matrix.

Determinants can only be calculated for square matrices. An e.g.
\(3 \times 2\) matrix can be viewed as a transformation mapping from 2-D
to 3-D space.\\

The \emph{dot product} of two vectors is calculated like a linear
transformation between a \(1 \times 2\) matrix and a \(2 \times 1\) matrix.
It therefor maps onto the 1-D Space and can be used as a measure of
collinearity.

The \emph{cross product} of two vectors is a perpendicular vector that
describes the parallelogram that the two vectors span. Its magnitude can
be seen as the area of the parallelogram. Beware: The order of the
vectors in the operation matters. The cross product can be expressed by
a determinant. If two vectors are collinear or perpendicular, the cross
product is zero.

\hypertarget{system-of-equations}{%
\subsubsection{System of equations}\label{system-of-equations}}

Linear algebra can help you solve systems of equations.

\[
\begin{array}{ll} 1x+2y+3z=4 \\ 4x+5y+6z=-7 \\8x + 9y +0z = 1 \end{array}
\quad  \rightarrow  \quad
\begin{bmatrix} 1 \quad 2 \quad 3 \\ 4 \quad 5 \quad 6 \\ 8 \quad \ 9 \quad 0 \end{bmatrix} 
\begin{bmatrix} x \\ y \\ z\end{bmatrix} = 
\begin{bmatrix} 4 \\ -7 \\ 1 \end{bmatrix} 
\quad \rightarrow \quad
A \vec{x} = \vec{v}
\]

You can imagine this as as searching a vector \(\vec{x}\) that will land
on \(\vec{v}\) after the transformation \(A\).

To find \(\vec{x}\) you need the \emph{inverse} of \(A\):

\[
A^{-1}A = \begin{bmatrix} 1 \quad 0 \\ 0 \quad 1 \end{bmatrix}
\]

You now multiply the matrix equation with \(A^{-1}\) and get:

\[
A^{-1} A \vec{x} = A^{-1} \vec{v}
\quad \rightarrow \quad
\vec{x} = A^{-1} \vec{v}
\]

\hypertarget{eigenvalues-and-eigenvectors}{%
\subsubsection{Eigenvalues and Eigenvectors}\label{eigenvalues-and-eigenvectors}}

For a linear transformation \(A\), the eigenvectors \(\vec{v}\) represent
the vectors that stay on their span (keep orientation) and the
eigenvalues \(\lambda\) are the scalars by which the eigenvectors get
scaled.

\[
A \vec{v} = \lambda \vec{v}
\]

Transforming \(\lambda\) to a scaled identity matrix \(I\) and factoring out
\(\vec{v}\), we get: \[
(A - \lambda I) \vec{v} =  \vec{0}
\] This tells us, that the transformation \((A - \lambda I)\) needs to map
the vector \(\vec{v}\) onto a lower dimension.

An \emph{eigenbasis} \(\lambda I\) is a basis where the basis vectors are
eigenvectors. They will sit on the diagonal of your basis matrix
(\(\rightarrow\) it will be a \emph{diagonal matrix}).

\hypertarget{EV_Dec}{%
\subsubsection{Eigenvalue decomposition}\label{EV_Dec}}

An \emph{eigen(value)decomposition} is the decomposition of a matrix into the
matrix of eigenvalues and eigenvectors.

\[
AU = U \Lambda  \quad \rightarrow \quad A = U \Lambda U^{-1}
\]

where \(U\) is the matrix of the eigenvectors of \(A\) and \(\Lambda\) is the
eigenbasis. Thus matrix operations can be computed more easily, since
\(\Lambda\) is a diagonal matrix.

\hypertarget{SVD1}{%
\subsubsection{Singular value decomposition}\label{SVD1}}

Singular Value decomposition is also applicable to a non-square
\(m \times n\)-matrix (with \(m\) rows and \(n\) columns). If you have a
matrix with rank \(r\), you can decompose it into

\[
A = U \Sigma V^T
\] where \(U\) is an orthogonal \(m \times r\) matrix, \(\Sigma\) is a
diagonal \(r \times r\) matrix and \(V^T\) is an orthogonal \(r \times n\)
matrix. \(U\) contains the \emph{left singular vectors}, \(V\) the \emph{right
singular vectors} and \(\Sigma\) the \(Singular Values\).\\
This decomposition technique can be used to approximate the original
matrix \(A\) with only the largest singular values. Thereby you can save
computation time in matrix operations without loosing a lot of
information.\\
For applications, please see \protect\hyperlink{SVD2}{SVD for lower dimensional mapping}.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{data-basics}{%
\chapter{Data Basics}\label{data-basics}}

\hypertarget{similarity-and-distance-measures}{%
\section{Similarity and Distance Measures}\label{similarity-and-distance-measures}}

Choosing the right distance measures is important for achieving good
results in statistics, predictions and clusterings.

\hypertarget{metrics}{%
\subsection{Metrics}\label{metrics}}

For a distance measure to be called a metric \(d\), the following criteria
need to be fulfilled:

\begin{itemize}
\item
  Positivity: \(d(x_1,x_2)≥0\)
\item
  \(d(x_1,x_2)=0 \text{ if and only if } x_1 = x_2\)
\item
  Symmetry: \(d(x_1, x_2) = d(x_2, x_1)\)
\item
  Triangle inequality: \(d(x_1, x_3) ≤ d(x_1, x_2) + d(x_2, x_3)\)
\end{itemize}

There may be distance measures that do not fulfill these criteria, but
those are not metrics.

\hypertarget{similarity-measures-on-vectors}{%
\subsection{Similarity measures on vectors}\label{similarity-measures-on-vectors}}

These measures are used in many objective functions to compare data
points.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ pairwise\_distances}
\NormalTok{X1 }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{]])}
\NormalTok{X2 }\OperatorTok{=}\NormalTok{ np.array([[}\DecValTok{2}\NormalTok{,}\DecValTok{4}\NormalTok{]])}
\NormalTok{pairwise\_distances(X1,X2, metric}\OperatorTok{=}\StringTok{"manhattan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The available metrics in sklearn are: `cityblock', `cosine',
`euclidean', `l1', `l2', `manhattan', and from scipy: `braycurtis',
`canberra', `chebyshev', `correlation', `dice', `hamming', `jaccard',
`kulsinski', `mahalanobis', `minkowski', `rogerstanimoto', `russellrao',
`seuclidean', `sokalmichener', `sokalsneath', `sqeuclidean', `yule'\\
More info:
\href{https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html}{scikit-learn.org}

\hypertarget{manhattan-distance}{%
\subsubsection{Manhattan distance}\label{manhattan-distance}}

The distance is the sum of the absolute differences of the components
(single coordinates) of the two points:
\[d(A, B) = \sum_{i=1}^d | A_i - B_i |\]

More info at
\href{https://en.wikipedia.org/wiki/Taxicab_geometry}{wikipedia.org}.

\hypertarget{hamming-distance}{%
\subsubsection{Hamming distance}\label{hamming-distance}}

This metric is used for pairs of strings and works equivalently to the
Manhattan distance. It is the number of positions that are different
between the strings.\\
More info at
\href{https://en.wikipedia.org/wiki/Hamming_distance}{wikipedia.org}.

\hypertarget{euclidian-distance}{%
\subsubsection{Euclidian distance}\label{euclidian-distance}}

\[d(A, B) = | A - B | = \sqrt{\sum_{i=1}^d (A_i-B_i)^2} \]

More info on the euclidian distance on
\href{https://en.wikipedia.org/wiki/Euclidean_distance}{wikipedia.org}.\\
The usefulness of this metric can deteriorate in high dimensional
spaces. See \href{https://en.wikipedia.org/wiki/Curse_of_dimensionality\#Distance_function}{curse of
dimensionality}

\hypertarget{chebyshev-distance}{%
\subsubsection{Chebyshev distance}\label{chebyshev-distance}}

The Chebyshev distance is the largest difference along any of the
components of the two vectors.

\[d(A, B) = \max_i(|A_i-B_i|) \]

More info at
\href{https://en.wikipedia.org/wiki/Chebyshev_distance}{wikipedia.org}.

\hypertarget{minkowski-distance}{%
\subsubsection{Minkowski Distance}\label{minkowski-distance}}

\[d(A, B) = (\sum_{i=1}^d |A_i-B_i|^p)^\frac{1}{p} \]

For \(p=2\) the Minkowski distance is equal to the Euclidian distance, for
\(p=1\) it corresponds to the Manhattan distance and it converges to the
Chebyshev distance for \(p \to \infty\). ~ More info at
\href{https://en.wikipedia.org/wiki/Minkowski_distance}{wikipedia.org}.

\hypertarget{preprocessing-data}{%
\section{Preprocessing data}\label{preprocessing-data}}

\hypertarget{standardization}{%
\subsection{Standardization}\label{standardization}}

Many machine learning models assume that the features are centered
around 0 and that all have a similar variance. Therefore the data has to
be centered and scaled to unit variance before training and prediction.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ StandardScaler}
\NormalTok{scaler }\OperatorTok{=}\NormalTok{ StandardScaler()}
\NormalTok{scaler.fit(input\_df)}
\end{Highlighting}
\end{Shaded}

More info:
\href{https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html}{scikit-learn.org}

Another option for scaling is normalization. This is used, when the
values have to fall strictly between a max and min value.\\
More info:
\href{https://scikit-learn.org/stable/modules/preprocessing.html\#normalization}{scikit-learn.org}

\hypertarget{encoding-categorical-features}{%
\subsection{Encoding categorical features}\label{encoding-categorical-features}}

The string values (e.g.~``male'', ``female'') of features have to be
converted into integers. This can be done by two methods:

\hypertarget{ordinal-encoding}{%
\subsubsection{Ordinal Encoding}\label{ordinal-encoding}}

An integer is assigned to each category (e.g.~``male''=0, ``female''=1)

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ OrdinalEncoder}
\NormalTok{ord\_enc }\OperatorTok{=}\NormalTok{ preprocessing.OrdinalEncoder()}
\NormalTok{ord\_enc.fit(X)}
\NormalTok{ord\_enc.transform(X)}
\end{Highlighting}
\end{Shaded}

More info:
\href{https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html\#sklearn.preprocessing.OrdinalEncoder}{scikit-learn.org}\\
This method is useful when the categories have an ordered relationship
(e.g.~``bad'', ``medium'', ``good''). If this is not the case (e.g.~``dog'',
``cat'', ``bunny'') this is to be avoided since the algorithm might deduct
an ordered relationship where there is none. For these cases
one-hot-encoding is to be used.

\hypertarget{one-hot-encoding}{%
\subsubsection{One-Hot Encoding}\label{one-hot-encoding}}

One-hot encoding assigns a separate feature-column for each category and
encodes it binarily (e.g.~if the sample is a dog, it has 1 in the
dog-column and 0 in the cat and bunny column).

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ OneHotEncoder}
\NormalTok{onehot\_enc }\OperatorTok{=}\NormalTok{ OneHotEncoder(handle\_unknown}\OperatorTok{=}\StringTok{\textquotesingle{}ignore\textquotesingle{}}\NormalTok{)}
\NormalTok{onehot\_enc.fit(X)}
\NormalTok{onehot\_enc.transform(X)}
\end{Highlighting}
\end{Shaded}

More info:
\href{https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html}{scikit-learn.org}\\

\hypertarget{imputing-missing-values}{%
\subsection{Imputing missing values}\label{imputing-missing-values}}

Some algorithms assume that all features of all samples have numerical
values. In these cases missing values have to be imputed (i.e.~inferred)
or (if affordable) the samples with missing feature values can be
deleted from the data set.

\hypertarget{iterative-imputor-by-sklearn}{%
\subsubsection{Iterative imputor by sklearn}\label{iterative-imputor-by-sklearn}}

For features with missing values, this imputor imputes the missing
values by modelling each feature using the existing values from the
other features. It uses several iterations until the results converge.\\
\textbf{!} This method scales with \(O(nd^3)\), where \(n\) is the number of
samples and \(d\) is the number of features.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.experimental }\ImportTok{import}\NormalTok{ enable\_iterative\_imputer }\CommentTok{\# necessary since the imputor is still experimental}
\ImportTok{from}\NormalTok{ sklearn.impute }\ImportTok{import}\NormalTok{ IterativeImputer}
\ImportTok{from}\NormalTok{ sklearn.ensemble }\ImportTok{import}\NormalTok{ RandomForestRegressor }
\NormalTok{rf\_estimator }\OperatorTok{=}\NormalTok{ RamdomForestRegressor(n\_estimators }\OperatorTok{=} \DecValTok{8}\NormalTok{, max\_depth }\OperatorTok{=} \DecValTok{6}\NormalTok{, bootstrap }\OperatorTok{=}\NormalTok{ true)}
\NormalTok{imputor }\OperatorTok{=}\NormalTok{ IterativeImputer(random\_state}\OperatorTok{=}\DecValTok{0}\NormalTok{, estimator }\OperatorTok{=}\NormalTok{ rf\_estimator, max\_iter }\OperatorTok{=} \DecValTok{25}\NormalTok{)}
\NormalTok{imputor.fit\_transform(X)}
\end{Highlighting}
\end{Shaded}

More info:
\href{https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html}{scikit-learn.org}\\

\hypertarget{splitting-in-training--and-test-data}{%
\section{Splitting in training- and test-data}\label{splitting-in-training--and-test-data}}

You need to split your training set into test- and training-samples. The
algorithm uses the training samples with the known label/target value
for fitting the parameters. The test-set is used to determine if the
trained algorithm performs well on new samples as well. You need to give
special considerations to the following points:

\begin{itemize}
\item
  Avoiding data or other information to leak from the training set to
  the test-set
\item
  Validating if the predictive performance deteriorates over time
  (i.e.~the algorithm will perform worse on new samples). This is
  especially important for models that make predictions for future
  events.
\item
  Conversely, sampling the test- and training-sets randomly to avoid
  introducing bias in the two sets.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# assuming you already imported the data and separated the label column:}
\ImportTok{from}\NormalTok{ sklearn.model\_selection }\ImportTok{import}\NormalTok{ train\_test\_split}
\NormalTok{X\_train, X\_test, y\_train, y\_test }\OperatorTok{=}\NormalTok{ train\_test\_split(X, y, test\_size}\OperatorTok{=}\FloatTok{0.33}\NormalTok{, random\_state}\OperatorTok{=}\DecValTok{42}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

More info:
\href{https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html}{scikit-learn.org}

\hypertarget{feature-selection}{%
\section{Feature selection}\label{feature-selection}}

Usually the label does not depend on all available features. To detect
causal features, remove noisy ones and reduce the running and training
costs of the algorithm, we reduce the amount of features to the relevant
ones. This can be done a priori (before training) or using wrapper
methods (integrated with the prediction algorithm to be used).\\
\textbf{!} There are methods that have feature selection already built-in,
such as decision trees.

\hypertarget{a-priori-feature-selection}{%
\subsection{A priori feature selection}\label{a-priori-feature-selection}}

\hypertarget{low-variance-threshold}{%
\subsubsection{Low variance threshold}\label{low-variance-threshold}}

A cheap method is to remove all features with variance below a
threshold.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.feature\_selection }\ImportTok{import}\NormalTok{ VarianceThreshold}
\NormalTok{selector }\OperatorTok{=}\NormalTok{ VarianceThreshold(threshold}\OperatorTok{=}\FloatTok{0.1}\NormalTok{)}
\NormalTok{selector.fit\_transform(X)}
\end{Highlighting}
\end{Shaded}

More info:
\href{https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html\#sklearn.feature_selection.VarianceThreshold}{scikit-learn.org}

\hypertarget{mutual_info}{%
\subsubsection{Mutual information}\label{mutual_info}}

This method works by choosing the features that have the highest
dependency between the features and the label.

\[ I(X, Y) =D_{KL} \left( P(X=x, Y=y), P(X=x) \otimes P(Y=y) \right) =\sum_{y \in Y} \sum_{x \in X}
    { P(X=x, Y=y) \log\left(\frac{P(X=x, Y=y)}{P(X=x)P(Y=y)}\right) }\]

where, \(D_{KL}\) is the \href{https://en.wikipedia.org/wiki/Kullback\%E2\%80\%93Leibler_divergence}{Kullback--Leibler
divergence}
(A measure of similarity between distributions). The \(\log\)-Term is for
quantifying how different the joint distribution is from the product of
the marginal distributions.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.feature\_selection }\ImportTok{import}\NormalTok{ SelectKBest}
\ImportTok{from}\NormalTok{ sklearn.feature\_selection }\ImportTok{import}\NormalTok{ mutual\_info\_classif }\CommentTok{\# for regression use mutual\_info\_regression}
\NormalTok{X\_new }\OperatorTok{=}\NormalTok{ SelectKBest(mutual\_info\_classif, k}\OperatorTok{=}\DecValTok{8}\NormalTok{).fit\_transform(X, y)}
\end{Highlighting}
\end{Shaded}

More \url{info:/}
\href{https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html}{scikit-learn.org}\\
\href{https://en.wikipedia.org/wiki/Mutual_information}{wikipedia.org/wiki/Mutual\_information}

\hypertarget{wrapper-methods}{%
\subsection{wrapper methods}\label{wrapper-methods}}

\hypertarget{greedy-feature-selection}{%
\subsubsection{Greedy feature selection}\label{greedy-feature-selection}}

Using greedy feature selection as a wrapper method, one commonly starts
with 0 features and adds the feature that returns the highest score with
the used classifier.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.feature\_selection }\ImportTok{import}\NormalTok{ SequentialFeatureSelector}
\ImportTok{from}\NormalTok{ sklearn.tree }\ImportTok{import}\NormalTok{ DecisionTreeClassifier}
\NormalTok{classifier }\OperatorTok{=}\NormalTok{ DecisionTreeClassifier()}
\NormalTok{selector }\OperatorTok{=}\NormalTok{ SequentialFeatureSelector(classifier, n\_features\_to\_select}\OperatorTok{=}\DecValTok{8}\NormalTok{)}
\NormalTok{selector.fit\_transform(X, y)}
\end{Highlighting}
\end{Shaded}

More info:
\href{https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html}{scikit-learn.org}

\hypertarget{advice-pitfalls}{%
\subsection{Advice \& Pitfalls}\label{advice-pitfalls}}

Selected advice from paper from \href{https://jmlr.csail.mit.edu/papers/volume3/guyon03a/guyon03a.pdf}{Guyon and
Elisseeff}:

\begin{itemize}
\item
  If you have domain knowledge: Use it.
\item
  Are your features commensurate (same proportion): Normalize them.
\item
  Do you suspect interdependent features: Construct conjunctive
  features or products of features.
\end{itemize}

Other advice:

\begin{itemize}
\item
  Features that are useless on their own, can be useful in combination
  with other features.
\item
  Using multiple redundant variables can be useful to reduce noise.
\item
  There are also models (e.g.~lasso regression, decision trees) that
  have feature selection built into the model (i.e.~by only allowing
  for a certain number of features to be used or penalizing the use of
  additional features).
\end{itemize}

\hypertarget{hyper-parameter-tuning}{%
\section{Hyper-parameter tuning}\label{hyper-parameter-tuning}}

The hyper-parameters (e.g.~kernel, gamma, number of nodes in tree) are
not trained by algorithm itself. An outer loop of hyper-parameter tuning
is needed to find the optimal hyper parameters.\\
\textbf{!} It is strongly recommended to separate another validation set from
the training set for hyper-parameter tuning (you'll end up with
training-, validation- and test-set). See \protect\hyperlink{crossval}{Cross Validation}
for best practice.

\hypertarget{grid-search}{%
\subsection{Grid search}\label{grid-search}}

The classic approach is exhaustive grid search: You create a grid of
hyperparameters and iterate over all combinations. The combination with
the best score is used in the end. This approach causes big
computational costs due to the combinatorial explosion.

\hypertarget{randomized-search}{%
\subsection{randomized search}\label{randomized-search}}

This approach is used, if there are too many combinations of
hyper-parameters for tuning. You allocate a budget of iterations and the
combinations of parameters are sampled randomly according to the
distributions you provide.

If you want to evaluate on a large set of hyperparameters, you can use a
halving strategy: You tune a large combination of parameters on few
resources (e.g.~samples, trees). The best performing half of candidates
is re-evaluated on twice as many resources. This continues until the
best-performing candidate is evaluated on the full amount of resources.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.ensemble }\ImportTok{import}\NormalTok{ RandomForestClassifier}
\ImportTok{from}\NormalTok{ sklearn.experimental }\ImportTok{import}\NormalTok{ enable\_halving\_search\_cv  }\CommentTok{\# since this method is still experimental}
\ImportTok{from}\NormalTok{ sklearn.model\_selection }\ImportTok{import}\NormalTok{ HalvingRandomSearchCV}
\ImportTok{from}\NormalTok{ sklearn.utils.fixes }\ImportTok{import}\NormalTok{ loguniform}

\NormalTok{rf\_clf }\OperatorTok{=}\NormalTok{ RandomForestClassifier()}

\NormalTok{param\_distributions }\OperatorTok{=}\NormalTok{ \{}\StringTok{"max\_depth"}\NormalTok{: [}\DecValTok{3}\NormalTok{, }\VariableTok{None}\NormalTok{],}
                       \StringTok{"min\_samples\_split"}\NormalTok{: loguniform(}\DecValTok{1}\NormalTok{, }\DecValTok{10}\NormalTok{)\}}
\NormalTok{hypa\_search }\OperatorTok{=}\NormalTok{ HalvingRandomSearchCV(rf\_clf, param\_distributions,}
\NormalTok{                               resource}\OperatorTok{=}\StringTok{\textquotesingle{}n\_estimators\textquotesingle{}}\NormalTok{,}
\NormalTok{                               max\_resources}\OperatorTok{=}\DecValTok{10}\NormalTok{,}
\NormalTok{                               n\_jobs}\OperatorTok{={-}}\DecValTok{1}\NormalTok{, }\CommentTok{\# important since hyper{-}parameter tuning is very costly}
\NormalTok{                               scoring }\OperatorTok{=} \StringTok{\textquotesingle{}balanced\_accuracy\textquotesingle{}}\NormalTok{,}
\NormalTok{                               random\_state}\OperatorTok{=}\DecValTok{0}\NormalTok{).fit(X, y)}
\end{Highlighting}
\end{Shaded}

More info:
\href{https://scikit-learn.org/stable/modules/grid_search.html\#searching-for-optimal-parameters-with-successive-halving}{scikit-learn.org}\\

\hypertarget{model-selection}{%
\section{Model selection}\label{model-selection}}

The candidates for hyper-parameters must not be evaluated on the same
data that you trained it on (over-fitting risk). Thus, we separate
another data-set from the training data: The validation set. This is
reduces the amount of training data drastically. Therefore we use the
approaches of Cross Validation and Bootstrapping.

\hypertarget{crossval}{%
\subsection{Cross Validation}\label{crossval}}

In k-fold Cross Validation, we split the training set into k sub-sets.
We train on the samples in k-1 sub-sets and validate using the data in
the remaining sub-set. We iterate until we have validated on each
sub-set once. We then average out the k scores we obtain.

\begin{figure}
\centering
\includegraphics[width=0.6\textwidth,height=\textheight]{figures/cross_validation.png}
\caption{Schema of the process for 5-fold Cross Validation. The data is first
split into training- and test-data. The training data is split into 5
sub-sets. The algorithm is trained on 4 sub-sets and evaluated on the
remaining sub-set. Each sub-set is used for validation once. \emph{Source:
\href{https://scikit-learn.org/stable/modules/cross_validation.html}{scikit-learn.org}.}}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn }\ImportTok{import}\NormalTok{ svm}
\ImportTok{from}\NormalTok{ sklearn.model\_selection }\ImportTok{import}\NormalTok{ cross\_val\_score}
\NormalTok{SVM\_clf }\OperatorTok{=}\NormalTok{ svm.SVC (kernel}\OperatorTok{=}\StringTok{\textquotesingle{}polynomial\textquotesingle{}}\NormalTok{)}
\NormalTok{cv\_scores }\OperatorTok{=}\NormalTok{ cross\_val\_score(SVM\_clf, X, y, cv }\OperatorTok{=} \DecValTok{7}\NormalTok{)}
\NormalTok{cv\_score }\OperatorTok{=}\NormalTok{ cv\_scores.mean()}
\end{Highlighting}
\end{Shaded}

More info:
\href{https://scikit-learn.org/stable/modules/cross_validation.html\#computing-cross-validated-metrics}{scikit-learn.org}

\textbf{!} If you have time-series data (and other clearly not i.i.d.) data,
you have to use \href{https://scikit-learn.org/stable/modules/cross_validation.html\#time-series-split}{special cross-validation
strategies}.
~ There are \href{https://scikit-learn.org/stable/modules/cross_validation.html\#time-series-split}{further
strategies}
worth considering.

\hypertarget{bootstrapping}{%
\subsection{Bootstrapping}\label{bootstrapping}}

Instead of splitting the data into k subsets, you can also just sample
data into training and validation sets.\\
More info:
\href{https://en.wikipedia.org/wiki/Bootstrapping_(statistics)}{wikipedia.org}.

\hypertarget{errors-in-machine-learning}{%
\section{Errors in machine learning}\label{errors-in-machine-learning}}

There are irreducible errors and reducible errors. Irreducible errors
stem from unknown variables or variables we have no data on. Reducible
errors are deviations from our model to its desired behavior and can be
reduced. Bias and variance are reducible errors.

\[\text{Error} = \text{Bias} + \text{Var} + \text{irr. Error}\]

\hypertarget{bias-and-variance}{%
\subsection{Bias and Variance}\label{bias-and-variance}}

\hypertarget{bias-of-an-estimator}{%
\subsubsection{Bias of an estimator}\label{bias-of-an-estimator}}

Bias tells you if your model oversimplifies the true relationship in
your data (underfitting).\\
You have a model with a parameter \(\hat{\theta}\) that is an estimator
for the true \(\theta\). You want to know whether your model over- or
underestimates the true \(\theta\) systematically.

\[\text{Bias}[\hat{\theta}]=\text{E}_{X|\mathcal{D}}[\hat{\theta}]- \theta\]

E.g. if the parameter captures how polynomial the model / relationship
of your data is, a too high value means that your model is
underfitting.\\

More info:
\href{https://en.wikipedia.org/wiki/Bias_of_an_estimator}{wikipedia.org}

\hypertarget{variance-of-an-estimator}{%
\subsubsection{Variance of an estimator}\label{variance-of-an-estimator}}

Variance tells you if your model learns from noise instead of the true
relationship in your data (overfitting).

\[\text{Var}[\hat{\theta}]=\text{E}_{X|\mathcal{D}}[(\text{E}_{X|\mathcal{D}}[\hat{\theta}]- \hat{\theta})^2]\]
i.e.~If you would bootstrap your data, it would show you how much your
parameter would jump around its mean, when it learns from the different
sampled sets.\\

Your goal is now to find the sweet spot between a too biased (too simple
model) and a model with too high variance (too complex model).\\

\begin{figure}
\centering
\includegraphics[width=0.6\textwidth,height=\textheight]{figures/Bias_and_variance_contributing_to_total_error.png}
\caption{Relationship between bias, variance and the total error. The minimum
of the total error lies at the best compromise between bias and
variance. \emph{Source: \href{https://commons.wikimedia.org/wiki/File:Bias_and_variance_contributing_to_total_error.svg}{User Bigbossfarin on
wikimedia.org.}.}}
\end{figure}

More info:
\href{https://en.wikipedia.org/wiki/Bias\%E2\%80\%93variance_tradeoff}{wikipedia.org}

\hypertarget{regularization}{%
\subsection{Regularization}\label{regularization}}

To combat overfitting, we can introduce a term into our loss-function
that penalizes complex models. For linear regression, our regularized
loss function is will be:

\[\min L(\hat{y},y)= \min_{W,b} f(WX+b,y)+\lambda R(W)\] where \(f\) is
the unregularized loss function, \(W\) is the weight matrix, \(X\) is the
sample matrix and \(b\) is the bias or offset term of the model (bias term
\(\neq\) bias of estimator!). \(R\) is the regularization function and
\(\lambda\) is a parameter controlling its strength.\\
i.e.~The regularized loss function punishes large weights \(W\) and leads
to flatter/smoother functions.\\

More info:
\href{https://en.wikipedia.org/wiki/Regularization_(mathematics)}{wikipedia.org}

\hypertarget{bagging}{%
\subsection{Bagging}\label{bagging}}

Train several instances of a complex estimator (aka. strong learner,
like large decision trees or KNN with small radius) on a subset of the
data. Then use a majority vote or average the scores for classifying to
get the final prediction. By training on different subsets and averaging
the results, the chances of overfitting are greatly reduced.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.ensemble }\ImportTok{import}\NormalTok{ BaggingClassifier}
\ImportTok{from}\NormalTok{ sklearn.neighbors }\ImportTok{import}\NormalTok{ KNeighborsClassifier}
\NormalTok{bagging }\OperatorTok{=}\NormalTok{ BaggingClassifier(KNeighborsClassifier(), max\_features}\OperatorTok{=}\FloatTok{0.5}\NormalTok{, n\_estimators}\OperatorTok{=}\DecValTok{20}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

More info:
\href{https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html}{scikit-learn.org}\\

A classic example for a bagging classifier is \href{https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html}{Random Forest
Classifier}
or its variant \href{https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html}{Extremely Randomized
Trees}
which further reduces variance and increases bias.

\hypertarget{boosting}{%
\subsection{Boosting}\label{boosting}}

Compared to bagging, we use weak learners that are not trained
independently of each other. We start with a single weak learner (e.g.~a
small decision tree) and repeat the following steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add an additional model and train it.
\item
  Increase weights of training samples that are falsely classified,
  decrease weights of correctly classified samples. (to be used by
  next added model.)
\item
  Reweight results from the models in the combined model to reduce the
  training error.
\end{enumerate}

The final model is an weighted ensemble of weak classifiers.\\
The most popular ones are \href{https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\#sklearn.ensemble.GradientBoostingClassifier}{gradient boosted decision
tree}
algorithms.

\hypertarget{stacking}{%
\subsection{Stacking}\label{stacking}}

Stacking closely resembles bagging: An ensemble of separately trained
base models is used to create an ensemble model. However, the continuous
(instead of discrete) outputs of commonly fewer heterogeneous models
(instead of same type of models) are used. The continuous outputs are
then fed into a final estimator (commonly logistic regression
classifier).

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.svm }\ImportTok{import}\NormalTok{ SVC}
\ImportTok{from}\NormalTok{ sklearn.neighbors }\ImportTok{import}\NormalTok{ KNeighborsClassifier}
\ImportTok{from}\NormalTok{ sklearn.tree }\ImportTok{import}\NormalTok{ DecisionTreeClassifier}
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LogisticRegression}
\ImportTok{from}\NormalTok{ sklearn.pipeline }\ImportTok{import}\NormalTok{ make\_pipeline}
\ImportTok{from}\NormalTok{ sklearn.ensemble }\ImportTok{import}\NormalTok{ StackingClassifier}

\NormalTok{classifiers }\OperatorTok{=}\NormalTok{ [}
\NormalTok{    (}\StringTok{\textquotesingle{}svc\textquotesingle{}}\NormalTok{, SVC()),}
\NormalTok{    (}\StringTok{\textquotesingle{}knn\textquotesingle{}}\NormalTok{, KNeighborsClassifier()),}
\NormalTok{    (}\StringTok{\textquotesingle{}dtc\textquotesingle{}}\NormalTok{, DecisionTreeClassifier())}
\NormalTok{    ]}
    
\NormalTok{clf }\OperatorTok{=}\NormalTok{ StackingClassifier(}
\NormalTok{    classifiers}\OperatorTok{=}\NormalTok{estimators, final\_estimator}\OperatorTok{=}\NormalTok{LogisticRegression()}
\NormalTok{    )}

\NormalTok{clf.fit(X, y)}
\end{Highlighting}
\end{Shaded}

More info:
\href{https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html}{scikit-learn.org}

\hypertarget{tips-for-machine-learning-projects}{%
\section{Tips for machine learning projects}\label{tips-for-machine-learning-projects}}

\hypertarget{general-advice}{%
\subsection{General advice}\label{general-advice}}

General advice for machine learning from \href{https://courses.cs.duke.edu/spring20/compsci527/papers/Domingos.pdf}{Pedro
Domingos}:

\begin{itemize}
\item
  Let your knowledge about the problem help you choose the candidate
  algorithms. E.g. You know the rules on which comparing samples makes
  most sense \(\rightarrow\) Choose instance based learners. If you know
  that statistical dependencies are relevant \(\rightarrow\) choose
  Graph based models.
\item
  Don't underestimate the impact of feature engineering: Many domain
  specific features can boost the accuracy.
\item
  Get more samples and candidate features (instead of focussing on the
  algorithm)
\item
  Don't confuse correlation with causation. Just because your model
  can predict something, it does not mean that the features cause the
  target and you thus cannot easily deduct a clear action from it.
\end{itemize}

\hypertarget{common-mistakes}{%
\section{Common mistakes}\label{common-mistakes}}

Be aware: This list will never capture everything that can go wrong. ;-)

\begin{itemize}
\item
  \href{https://scikit-learn.org/stable/common_pitfalls.html\#data-leakage}{\textbf{Data
  Leakage}}\textbf{:}
  Information from Samples in your test data have leaked into your
  training data.

  \begin{itemize}
  \tightlist
  \item
    You have not deleted duplicates beforehand
  \item
    You falsely assumed that your samples where drawn independently
    and have sampled the training set randomly. (E.g. multiple
    samples from the same patient, time series data)
  \item
    You have the class label encoded in the training features in a
    way that you will not find in ``Nature''.
  \item
    You just used the wrong training / test set while programming.
  \item
    You did feature engineering like finding n-grams or Max, Min of
    data using your test-set data.
  \item
    \textbf{Remedy:} Careful preliminary data analysis, deduplication,
  \end{itemize}
\item
  \textbf{Using bad quality measures on unbalanced data:} E.g. Accuracy on
  unbalanced data is not a reasonable quality measure.
\item
  \href{https://scikit-learn.org/stable/common_pitfalls.html\#inconsistent-preprocessing}{\textbf{Inconsistent
  preprocessing}}\textbf{:}
  If you preprocess your training data in a certain way, you have to
  do the same with the test- and prediction-data.

  \begin{itemize}
  \tightlist
  \item
    \textbf{Remedy}: Use one preprocessing pipeline that you can use for
    training, testing and prediction.
  \end{itemize}
\item
  \textbf{Curse of dimensionality:}

  \begin{itemize}
  \tightlist
  \item
    You use too many features for the amount of samples that you
    have
  \item
    Your distance measure is not suitable for high-dimensional space
    (e.g.~Hamming distance, Euclidean distance)
  \item
    \textbf{Remedy:} Use lower-dimensional mapping.
  \end{itemize}
\item
  \textbf{Overfitting:}

  \begin{itemize}
  \tightlist
  \item
    You use a too complex algorithm (too many degrees of freedom)
    for the amount of data you have
  \item
    You have too many features
  \item
    \textbf{Remedy:} Get more samples, reduce the dimensionanlity,
    feature selection, regularization, bagging, boosting, stacking.
  \end{itemize}
\item
  \textbf{Bad Data:}

  \begin{itemize}
  \tightlist
  \item
    Your data is not representative of what you would find in the
    ``real world''. (skewed population, too old data, only of specific
    sensors, locations\ldots)
  \item
    Your have many missing values among your features.
  \item
    The data that you have is only remotely linked to the target
    that you want to predict.
  \item
    There are erroneous entries in your data.
  \item
    \textbf{Remedy:} Clean data at source, impute data, clean data during
    preprocessing, get more representative data, limit scope of
    application.
  \end{itemize}
\end{itemize}

\hypertarget{classification-methods}{%
\chapter{Classification Methods}\label{classification-methods}}

Classification is the assignment of objects (data points) to categories
(classes). It requires a data set (i.e.~training set) of points with
known class labels. If the class labels are not known you can instead
group the data using clustering algorithms (chapter
\protect\hyperlink{Clusteringux5cux2520Methods}{3}).

\hypertarget{evaluation-of-classifiers}{%
\section{Evaluation of Classifiers}\label{evaluation-of-classifiers}}

\hypertarget{confusion-matrix}{%
\subsection{Confusion matrix}\label{confusion-matrix}}

This gives a quick overview on the distribution of true positives
(\(TP\)), false positives (\(FP\)) , \(TN\) true negatives, \(FN\) false
negatives.

\hypertarget{basic-quality-measures}{%
\subsection{Basic Quality Measures}\label{basic-quality-measures}}

\begin{itemize}
\item
  \(\text{Accuracy / Success Rate} = \frac{ \text{correct predictions}}{\text{total predictions}} = \frac{ \text{TP}+\text{TN}}{\text{TP} + \text{TN}+\text{FP}+\text{FN}}\)\\
  This metric should only be used in this pure form, when the number
  of positive and negative samples are balanced.
\item
  \(\text{Precision} = \frac{\text{TP}}{\text{TP}+\text{FP}}\)\\
  i.e.~How many of your positive predictions are actually positive?
\item
  \(\text{True positive rate / Recall / Sensitivity} = \frac{\text{TP}}{\text{TP}+\text{FN}}\)\\
  i.e.~How many of the positive samples did you catch?
\item
  \(\text{True negative rate / Specificity / Selectivity} = \frac{\text{TN}}{\text{TN}+\text{FP}}\)\\
  i.e.~How many of the negative samples did you catch as negative
  (i.e.~are truly negative)?
\item
  \(\text{F-score} = 2 \frac{\text{precision} * \text{recall}}{\text{precision}+\text{recall}}\)\\
  This is useful in cases of unbalanced classes to balance the
  trade-off between precision and recall.
\end{itemize}

\hypertarget{area-under-the-curve}{%
\subsection{Area under the Curve}\label{area-under-the-curve}}

This class of measures represents the quality of the classifier for
different threshold values \(\theta\) by calculating the area under the
curve spanned by different quality measures.

\hypertarget{area-under-the-receiver-operating-characteristics-curve-auroc-or-auc}{%
\subsubsection{Area under the Receiver Operating Characteristics Curve (AUROC or AUC)}\label{area-under-the-receiver-operating-characteristics-curve-auroc-or-auc}}

The AUC can be interpreted as follows: When the classifier gets a
positive and a negative point, the AUC shows the probability that the
classifier will give a higher score to the positive point. A perfect
classifier has an AUC of 1, and AUC of 0.5 represents random guessing.

\textbf{!} This measure is not sensitive to class imbalance!

\begin{figure}
\centering
\includegraphics[width=0.44\textwidth,height=\textheight]{figures/Roc_curve.png}
\caption{Area under the precision recall curve. Source: \href{https://commons.wikimedia.org/wiki/File:Roc_curve.svg}{user cmglee on
wikipedia.org}}
\end{figure}

\hypertarget{area-under-the-precision-recall-curve-auprc-average-precision-avep}{%
\subsubsection{Area under the Precision-Recall Curve (AUPRC) / Average Precision (AveP)}\label{area-under-the-precision-recall-curve-auprc-average-precision-avep}}

This measure can be used for unbalanced data sets. It represents the
average precision as a function of the recall. The value of 1 represents
a perfect classifier.

\begin{figure}
\centering
\includegraphics[width=0.65\textwidth,height=\textheight]{figures/pr_curve.png}
\caption{The precision-recall curve. Source:
\href{https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html\#:~:text=The\%20precision\%2Drecall\%20curve\%20shows,a\%20low\%20false\%20negative\%20rate.}{scikit-learn.org}}
\end{figure}

\hypertarget{handling-unbalanced-data}{%
\subsection{Handling Unbalanced Data}\label{handling-unbalanced-data}}

Having many more samples in one class than the others during training
can lead to high accuracy values event though the classifier performs
poorly on the smaller classes. You can handle the unbalance by:

\begin{itemize}
\item
  up-sampling the smaller data set (creating more artificial samples
  for that class)
\item
  giving more weight to the samples in the smaller data set
\item
  using a quality measure that is sensitive to class imbalance
\end{itemize}

Oversampling using imbalanced-learn (see: )

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ imblearn.over\_sampling }\ImportTok{import}\NormalTok{ RandomOverSampler}
\NormalTok{ros }\OperatorTok{=}\NormalTok{ RandomOverSampler(random\_state}\OperatorTok{=}\DecValTok{0}\NormalTok{)}
\NormalTok{features\_resampled, labels\_resampled }\OperatorTok{=}\NormalTok{ ros.fit\_resample(df[feature\_cols], df[label\_col])}
\end{Highlighting}
\end{Shaded}

Sensitivity, specificity, precision, recall, support and F-score

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_true }\OperatorTok{=}\NormalTok{ df[label\_col]}
\NormalTok{y\_pred }\OperatorTok{=}\NormalTok{ classifier.predict(df[feature\_cols])}

\ImportTok{from}\NormalTok{ imblearn.metrics }\ImportTok{import}\NormalTok{ sensitivity\_specificity\_support}
\NormalTok{sensitivity, specificity, support }\OperatorTok{=}\NormalTok{ sensitivity\_specificity\_support(y\_true, y\_pred) }

\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ precision\_recall\_fscore\_support}
\NormalTok{precision, recall, fscore, support }\OperatorTok{=}\NormalTok{ precision\_recall\_fscore\_support(y\_true, y\_pred) }
\end{Highlighting}
\end{Shaded}

\hypertarget{classification-algorithms}{%
\section{Classification Algorithms}\label{classification-algorithms}}

\hypertarget{nearest-neighbors-classifier}{%
\subsection{Nearest Neighbors Classifier}\label{nearest-neighbors-classifier}}

This classifier predicts the class label using the most common class
label of its \(k\) nearest neighbors in the training data set.

\textbf{Pros:}

\begin{itemize}
\tightlist
\item
  Classifier does not take time for training.
\item
  Can learn complex decision boundaries.
\end{itemize}

\textbf{Cons:}

\begin{itemize}
\tightlist
\item
  The prediction is time consuming and scales with n.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn }\ImportTok{import}\NormalTok{ KNeighborsClassifier}
\NormalTok{kn\_model }\OperatorTok{=}\NormalTok{ KNeighborsClassifier(n\_neighbors}\OperatorTok{=}\DecValTok{5}\NormalTok{)}
\NormalTok{kn\_model.fit(X, y)}
\NormalTok{kn\_model.predict([[}\DecValTok{5}\NormalTok{,}\DecValTok{1}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

\href{https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html}{scikit-learn.org}\\

\hypertarget{naive-bayes-classifier}{%
\subsection{Naive Bayes Classifier}\label{naive-bayes-classifier}}

Naive Bayes classifies works on the assumption that the features are
conditionally independent given the class label. For every point a
simplified version of Bayes rule is used:

\[P(Y=y_i|X=x) \propto P(X=x|Y=y_i) * P(Y=y_i) \] where \(Y\) is the RV
for the class label and \(X\) is the RV that contains the feature values.
This holds since \(P(X=x)\) is the same for all classes. Since the
different features \(X_j\) are assumed to be independent they can be
multiplied out. The label \(y_i\) with the highest probability is the
predicted class label:
\[\arg \max_{y_i} P(Y=y_i|X=x) \propto P(Y=y_i) \prod_{j=1}^{d} P(X_j=x_j|Y=y_i)  \]
One usually estimates the value of \(P(Y)\) as the ferquency of the
different classes in the training data or assumes that all classes are
equally likely.\\
To estimate the \(P(X_j=x_j|Y=y_i)\) the following distributions are
commonly used: - For binary features: Bernoulli distribution - For
discrete features: Multinomial distribution - For continuous features:
Normal / Gaussian distribution

For discrete features, you need to use a \href{https://scikit-learn.org/stable/modules/naive_bayes.html\#multinomial-naive-bayes}{smoothing
prior}
(add 1 to every feature count) to avoid 0 probabilities for samples with
features being 0 in the training data.

\textbf{Pros:}

\begin{itemize}
\item
  Naive Bayes training is fast.
\item
  Combine descrete and continuous features since a different
  distribution can be used for each feature.
\item
  You can have straight decision boundaries (when classes have same
  variance), circular decision boundaries (different variance, same
  mean) and parabolic decision boundaries (different mean, different
  variance).
\end{itemize}

\textbf{Cons:}

\begin{itemize}
\item
  The probability estimates from Naive Bayes are \href{https://scikit-learn.org/stable/modules/naive_bayes.html\#naive-bayes}{usually
  bad}.
\item
  The independence assumption between the features is usually not
  given in real life.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.model\_selection }\ImportTok{import}\NormalTok{ train\_test\_split}
\ImportTok{from}\NormalTok{ sklearn.naive\_bayes }\ImportTok{import}\NormalTok{ GaussianNB}
\NormalTok{clf }\OperatorTok{=}\NormalTok{ GaussianNB()}
\NormalTok{clf.fit(X, y)}
\end{Highlighting}
\end{Shaded}

More info:
\href{https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html}{scikit-learn.org}\\

\hypertarget{linear-discriminant-analysis-lda}{%
\subsection{Linear discriminant analysis (LDA)}\label{linear-discriminant-analysis-lda}}

Contrary to Naive Bayes, the features in LDA are not assumed to be
independently distributed. As with Bayes rule a distribution for each
class is calculated according to Bayes rule. \(P(X=x|Y=y_i)\) is modeled
as a multivariate Gaussian distribution. The Gaussians for each class
are assumed to be the same. The log-posterior can be simplified to:

\[log(P(y=y_i|x) = - \frac{1}{2} (x-\mu_i)^t \Sigma^{-1}(x-\mu_i)+\log P(y=y_i)\]
\(\mu_i\) is the mean of class \(i\), \((x-\mu_i)^t \Sigma^{-1}(x-\mu_i)\)
corresponds to the \href{https://en.wikipedia.org/wiki/Mahalanobis_distance}{Mahalanobis
distance}. Thus, we
assign the point to the class whose distribution it is closest to.\\
LDA can also be thought of projecting the data into a space with \(k-1\)
dimensions (\(k\) being number of classes). More info:
\href{https://en.wikipedia.org/wiki/Linear_discriminant_analysis}{wikipedia.org}.
It can also be used as a dimensionality reduction method.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.discriminant\_analysis }\ImportTok{import}\NormalTok{ LinearDiscriminantAnalysis}
\NormalTok{clf }\OperatorTok{=}\NormalTok{ LinearDiscriminantAnalysis()}
\NormalTok{clf.fit(X, y)}
\end{Highlighting}
\end{Shaded}

More info:
\href{https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html}{scikit-learn.org}\\

\hypertarget{support-vector-classifier-svc}{%
\subsection{Support Vector Classifier (SVC)}\label{support-vector-classifier-svc}}

SVCs use hyperplanes to separate data points according to their class
label with a maximum margin (\(M\)) between the separating hyperplane
(\(x^T\beta + \beta_0=0\)) and the points. If points cannot be perfectly
separated by the decision boundary, a soft margin SVM is used with a
slack variable \(\xi\) that punishes points in the margin or on the wrong
side of the hyperplane. The optimization problem is given by
\citep{Hastie2009} : \[\begin{split}
            \max_{\beta, \beta_0, \beta=1} M, \\
            \text{subject to } y_i(x_i^T \beta + \beta_0) \ge 1 - \xi_i, \quad \forall i, \\\xi_i \ge 0, \quad \sum \xi_i \le constant, \quad i= 1, ..., N, 
        \end{split}\] where \(\beta\) are the coefficients and \(x\) are the
\(N\) data points. The support vectors are the points that determine the
orientation of the hyperplane (i.e.~the closest points). The
classification function is given by:
\[G(x) = \text{sign}[x^T\beta + \beta_0]\] If you only calculate the
inner part of the function you can get the distance of a point to your
hyperplane (in SKlearn you need to divide by the norm vector \(w\) of your
hyperplane to get the true distance). To get the probability of a point
being in a class, you can use Platt's algorithm \citep{Platt1999}. SVMs are
sensitive to the scaling of the features. Therefore, the data should be
normalized before classification.\\

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn }\ImportTok{import}\NormalTok{ svm}
\CommentTok{\# train the model}
\NormalTok{svc\_model }\OperatorTok{=}\NormalTok{ svm.SVC()}
\NormalTok{svc\_model.fit(train\_df[feautre\_cols], train\_df[label\_col])}
\CommentTok{\# test the model}
\NormalTok{y\_predict }\OperatorTok{=}\NormalTok{ svc\_model.predict(test\_df[feature\_cols])}
\end{Highlighting}
\end{Shaded}

\hypertarget{decision-trees}{%
\subsection{Decision Trees}\label{decision-trees}}

A decision tree uses binary rules to recursively split the data into
regions that contain only a single class.

\begin{figure}
\centering
\includegraphics[width=0.6\textwidth,height=\textheight]{figures/Decision_Tree.jpg}
\caption{Decision trees work like flowcharts and have a root (the top node),
branches (possible outcomes of a test), nodes (tests on one attribute),
leafs (the class labels). This one shows the decision tree for the
classifier predicting if a patient survives the sinking of the Titanic.
Source: \href{https://commons.wikimedia.org/wiki/File:Decision_Tree.jpg}{user Gilgoldm on
wikipedia.org}}
\end{figure}

\textbf{Pros:}

\begin{itemize}
\item
  Interpretable results, if trees are not too big.
\item
  Cheap to train and predict.
\item
  Can handle categorical and continuous data at the same time.
\item
  Can be used for \href{https://scikit-learn.org/stable/modules/tree.html\#multi-output-problems}{multi-output
  problems}
  (e.g.~color and shape of object).
\end{itemize}

\textbf{Cons:}

\begin{itemize}
\tightlist
\item
  Overfitting risks
\item
  Some concepts are hard to learn (X-OR relationships, Decision
  boundaries are not smooth)
\item
  Unstable predictions: Small changes in data can lead to vastly
  different decision trees.
\end{itemize}

\textbf{Tips:} - Doing PCA helps the tree find separating features. -
Visualize the produced tree. - Setting a lower boundary on the
split-sizes of the data, reduces the chance of overfitting. - Balance
the dataset or weight the samples according to class sizes to avoid
constructing biased trees.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.tree }\ImportTok{import}\NormalTok{ DecisionTreeClassifier}
\NormalTok{clf }\OperatorTok{=}\NormalTok{ DecisionTreeClassifier(max\_depth}\OperatorTok{=}\DecValTok{10}\NormalTok{, min\_samples\_split}\OperatorTok{=}\FloatTok{0.01}\NormalTok{, class\_weight}\OperatorTok{=}\StringTok{"balanced"}\NormalTok{)}
\NormalTok{clf }\OperatorTok{=}\NormalTok{ clf.fit(X, Y)}
\end{Highlighting}
\end{Shaded}

More info:
\href{https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html}{scikit-learn.org}\\

Due to the overfitting risk and the instability, ensembles of decision
trees are commonly used.

\hypertarget{random-forests}{%
\subsubsection{Random forests}\label{random-forests}}

Random forests are a version of a \protect\hyperlink{bagging}{bagging} classifier
employing decision trees. To reduce the variance, the separate trees can
be assigned a limited number of features as well.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.ensemble }\ImportTok{import}\NormalTok{ RandomForestClassifier}
\NormalTok{clf }\OperatorTok{=}\NormalTok{ RandomForestClassifier(max\_depth}\OperatorTok{=}\DecValTok{10}\NormalTok{, max\_features}\OperatorTok{=}\StringTok{"sqrt"}\NormalTok{, class\_weight}\OperatorTok{=}\StringTok{"balanced"}\NormalTok{)}
\NormalTok{clf.fit(X, y)}
\end{Highlighting}
\end{Shaded}

More info:
\href{https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html}{scikit-learn.org}\\

\hypertarget{gradient-boosted-decision-trees}{%
\subsubsection{Gradient boosted decision trees}\label{gradient-boosted-decision-trees}}

Gradient boosted decision tree models are a form of
\protect\hyperlink{boosting}{boosting} employing decision trees.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ lightgbm }\ImportTok{as}\NormalTok{ lgbm}
\NormalTok{clf }\OperatorTok{=}\NormalTok{ lgbm.LGBMClassifier(class\_weight}\OperatorTok{=} \StringTok{"balanced"}\NormalTok{)}
\NormalTok{clf.fit(X, y)}
\end{Highlighting}
\end{Shaded}

More info: \href{https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html\#lightgbm-lgbmclassifier}{lightgbm
documentation},
\href{https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html}{Parameter
tuning},\\
\href{https://neptune.ai/blog/lightgbm-parameters-guide}{Further Parameter
tuning}\\
Similar model: \href{https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html}{scikit-learn.org}\\

\hypertarget{unsupervised-learning}{%
\chapter{Unsupervised Learning}\label{unsupervised-learning}}

\hypertarget{custering-methods}{%
\section{Custering Methods}\label{custering-methods}}

Clustering methods are used to group data when no class labels are
present. You thereby want to learn an intrinsic structure of the data.

\hypertarget{metrics-for-clustering-algorithms}{%
\subsection{metrics for Clustering algorithms}\label{metrics-for-clustering-algorithms}}

\hypertarget{silhouette-coefficient}{%
\subsubsection{Silhouette coefficient}\label{silhouette-coefficient}}

The silhouette coefficient compares the average distance of a point and
the points in its own cluster \(d(x,\mu_{C})\) to the average distance
between the point and and the points of the second nearest Cluster
\(d(x,\mu_{C'})\).

\[s(x) = \frac{d(x,\mu_{C'})-d(x,\mu_{C})}{\max(d(x,\mu_{C}), d(x,\mu_{C'}))}\]
where \(C\) is the own cluster and \(C'\) is the second nearest cluster. If
a point is clearly in its own cluster, \(s(x)\) is close to \(1\). If a
point is between two clusters, \(s(x)\) is close to 0. If a point is
closer to another cluster, \(s(x)\) is negative.\\
By varying the number of clusters, one can find the number with the
highest silhouette coefficients.

\textbf{Pros:}

\begin{itemize}
\tightlist
\item
  The score is high for dense and highly separated clusters.
\end{itemize}

\textbf{Cons:}

\begin{itemize}
\tightlist
\item
  The silhouette coefficient is mainly suitable for convex clusters,
  since it gives high values to this kind of clusters.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ silhouette\_score}
\ImportTok{from}\NormalTok{ sklearn.cluster }\ImportTok{import}\NormalTok{ KMeans}
\NormalTok{clu }\OperatorTok{=}\NormalTok{ KMeans(n\_clusters}\OperatorTok{=}\DecValTok{4}\NormalTok{)}
\NormalTok{clu.fit(X)}
\NormalTok{labels }\OperatorTok{=}\NormalTok{ clu.labels\_}
\NormalTok{silhouette\_score(X, labels, metric}\OperatorTok{=}\StringTok{\textquotesingle{}manhattan\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

More info:
\href{https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html}{scikit-learn.org}\\

A faster alternative is the \href{https://scikit-learn.org/stable/modules/generated/sklearn.metrics.davies_bouldin_score.html}{Davies-Bouldin
score},
where values closer to 0 indicate a better clustering.

\hypertarget{adjusted-mutual-information-score}{%
\subsubsection{Adjusted mutual information score}\label{adjusted-mutual-information-score}}

If you have labelled samples, you can use the \protect\hyperlink{mutual_info}{mutual information
score} to test if the classes correspond to your clusters.
The \emph{adjusted} mutual information score adjusts for chance.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{ adjusted\_mutual\_info\_score}
\NormalTok{adjusted\_mutual\_info\_score(Y, clusters)}
\end{Highlighting}
\end{Shaded}

\hypertarget{k-means-clustering}{%
\subsection{K-Means Clustering}\label{k-means-clustering}}

Goal: Divide data into K clusters so that the variance within the
clusters is minimized. The objective function:

\[V(D) = \sum_{i=1}^k \sum{x_j \in C_i} (x_j - \mu_i)^2,\] where \(V\) is
the variance, \(C_i\) is a cluster, \(\mu_i\) is a cluster mean, \(x_j\) is a
datapoint. The algorithm works as follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Assign the data to k initial clusters.
\item
  Calculate the mean of each cluster.
\item
  Assign the data points to the closest cluster mean.
\item
  If a point changed its cluster, repeat from step 2.
\end{enumerate}

\begin{figure}
\hypertarget{CDF}{%
\centering
\includegraphics[width=0.6\textwidth,height=\textheight]{./figures/kMeans.png}
\caption{Data from the \emph{Iris flower data set} clustered into 3 clusters using
k-Means. On the right the data points have been assigned to their actual
species. \emph{Figure from \href{https://commons.wikimedia.org/wiki/File:Autoencoder_schema.png}{user Chire on
wikimedia.org}.}}\label{CDF}
}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.cluster }\ImportTok{import}\NormalTok{ KMeans}
\NormalTok{kmeans }\OperatorTok{=}\NormalTok{ KMeans(n\_clusters}\OperatorTok{=}\DecValTok{4}\NormalTok{)}
\NormalTok{kmeans.fit(X)}
\NormalTok{kmeans.predict([[}\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

More info:
\href{https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html}{scikit-learn.org}\\

A faster alternative is \href{https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MiniBatchKMeans.html}{mini batch
K-Means}.

\hypertarget{graph-based-clustering}{%
\subsection{Graph-Based Clustering}\label{graph-based-clustering}}

You represent data set \(D\) as a graph \(G=(V,E)\) and divide it up in
connected sub-graphs that represent your clusters. Each edge \(e_{ij}\)
(between nodes \(v_i\) and \(v_j\)) has a weight \(w_{ij}\) (which is commonly
a similarity or distance measure).

\hypertarget{basic-graph-based-clustering}{%
\subsubsection{Basic Graph-Based Clustering}\label{basic-graph-based-clustering}}

The basic algorithm works like this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Define a weight-threshold \(\theta\).
\item
  For all edges: if \(w_{ij}\) \textgreater{} \(\theta\): remove \(e_{ij}\).
\item
  If nodes are connected by a path (found via \emph{depth first search}):
  Assign them to the same cluster.
\end{enumerate}

\hypertarget{dbscan}{%
\subsubsection{DBScan}\label{dbscan}}

\emph{Density-Based Spatial Clustering of Applications with Noise} is a more
noise robust version of basic graph-based clustering. You create
clusters based on dense and connected regions. It works like this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  A point is a \emph{core point} if at least \(\text{minPts}\) are within a
  radius of \(\epsilon\) of the point (including the point itself).
\item
  A point is \emph{directly reachable} if it is not a \emph{core point} but
  within \(\epsilon\) from a \(core point\).
\item
  All other points are not part of the cluster (and may not be part of
  any cluster).
\end{enumerate}

\textbf{!} For points between clusters, the assignment to a cluster depends
on the order of point assignments.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.cluster }\ImportTok{import}\NormalTok{ DBSCAN}
\NormalTok{dbscan }\OperatorTok{=}\NormalTok{ DBSCAN(eps}\OperatorTok{=}\DecValTok{3}\NormalTok{, min\_samples}\OperatorTok{=}\DecValTok{4}\NormalTok{)}
\NormalTok{dbscan.fit(X)}
\end{Highlighting}
\end{Shaded}

More info:
\href{https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html}{scikit-learn.org}\\

There is a newer version of this algorithm (\href{https://hdbscan.readthedocs.io/en/latest/basic_hdbscan.html}{Hierarchical
DBSCAN}),
that allows for clusters with varying density, more robustness in
cluster assignment and makes tuning \(\epsilon\) unnecessary.

\hypertarget{cut-based-clustering}{%
\subsubsection{Cut-Based Clustering}\label{cut-based-clustering}}

You introduce a \textbf{adjacency/similarity} matrix \(W\) (measures similarity
between data points) and define the number of clusters \(k\). You now try
to minimize the weight of edges \(\kappa\) between the clusters \(C\) (equal
to cutting edges between nodes that are least similar):

\[\begin{aligned}
                \begin{split}  
                    \min \frac{1}{2} \sum_{a=1}^k \sum_{b=1}^k \kappa(C_a, C_b) \\
                    \text{where } \kappa(C_a, C_b) = \sum_{v_i \in C_a , v_j \in C_b , a \neq b} W_{ij} \\ 
                    \text{ and } \kappa(C_a, C_a) = 0
                \end{split}
            \end{aligned}\] \(\rightarrow\) You only add up the
similarities/edge-weights between your clusters (but not within your
clusters).\\
For constructing the similarity matrix, different kernels can be used
(commonly the linear kernel or the Gaussian kernel).

\hypertarget{spectral-clustering}{%
\subsection{Spectral Clustering}\label{spectral-clustering}}

Spectral clustering works by non-linearly mapping the
matrix-representation of the graph onto a lower-dimensional space based
on its spectrum (set of eigenvectors) and group the points there. The
mapping preserves local distances, i.e.~close points stay close to each
other after the mapping. It employs three steps: Preprocessing,
decomposition and grouping.

\textbf{Preprocessing}

We create a Laplacian matrix \(L\) (Laplacian operator in matrix form,
measuring how strongly a vertex differs from nearby vertices (because
the edges are similarity measures)): \[L = D - W\]
\[D_{ij} = \begin{cases}
        \sum_{j=1}^N W_{ij} \\
        0 \text{ if } i \neq j
    \end{cases}\] where \(D\) is the degree matrix (the (weighted) degree
of each node is on the diagonal) and \(W\) is the adjacency/similarity
matrix (measures similarity between data points).

\textbf{Decomposition}

You first normalize the Laplacian to avoid big impacts of highly
connected vertices/nodes. More info on the calculation on
\href{https://en.wikipedia.org/wiki/Laplacian_matrix\#Laplacian_matrix_normalization}{wikipedia.org}.

We make \protect\hyperlink{EV_Dec}{eigenvalue decomposition}:

\[L U = \Lambda U \quad \rightarrow \quad L = U \Lambda U^{-1} \]

where \(U\) is the matrix of eigenvectors and \(\Lambda\) is the diagonal
matrix of eigenvalues. You can now find a lower-dimensional embedding by
choosing the \(k\) smallest non-zero eigenvalues. The final data is now
represented as a matrix of k eigenvectors.

\textbf{Grouping}

You have multiple options:

\begin{itemize}
\item
  You can cut the graph by using the chosen eigenvectors and splitting
  at 0 or median value.
\item
  You get the final cluster assignments by normalizing the now
  k-dimensional data and applying k-means clustering to it.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.cluster }\ImportTok{import}\NormalTok{ SpectralClustering}
\NormalTok{scl }\OperatorTok{=}\NormalTok{ SpectralClustering(n\_clusters}\OperatorTok{=}\DecValTok{4}\NormalTok{,}
\NormalTok{        affinity}\OperatorTok{=}\StringTok{\textquotesingle{}rbf\textquotesingle{}}\NormalTok{,}
\NormalTok{        assign\_labels}\OperatorTok{=}\StringTok{\textquotesingle{}cluster\_qr\textquotesingle{}}\NormalTok{, }\CommentTok{\# assigns labels directly from Eig vecs,}
\NormalTok{        n}\OperatorTok{{-}}\NormalTok{jobs }\OperatorTok{=} \OperatorTok{{-}}\DecValTok{1}\NormalTok{)}
\NormalTok{scl.fit(X)}
\end{Highlighting}
\end{Shaded}

More info:
\href{https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html}{scikit-learn.org}\\

\hypertarget{SSP}{%
\subsection{Sparse Subspace Clustering (SSP)}\label{SSP}}

The underlying assumption of SSP is that the different clusters reside
in different subspaces of the data. Clusters are therefore perpendicular
to each other and points in a cluster can only be reconstructed by
combinations of points in the same cluster (\(\rightarrow\)
self-expressiveness, the reconstruction vectors ought to be sparse). For
each point you try to find other points that can be used to recreate
that point - these then form the same cluster. Doing that for all points
gives you a data matrix \(X\) and a matrix of reconstruction vectors \(V\):

\[X = X*V\text{ s.t. diag}(V)=0.\]

You now try to minimize the V-matrix according to the L1-norm (giving
you a sparse matrix). This matrix can then be used for e.g.~spectral
clustering.

More details in the \href{https://ieeexplore.ieee.org/document/7780794}{original paper on
SSC-OMP}.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ cluster.selfrepresentation }\ImportTok{import}\NormalTok{ SparseSubspaceClusteringOMP}
\NormalTok{ssc }\OperatorTok{=}\NormalTok{ SparseSubspaceClusteringOMP(n\_clusters}\OperatorTok{=}\DecValTok{3}\NormalTok{,affinity}\OperatorTok{=}\StringTok{"symmetrize"}\NormalTok{)}
\NormalTok{ssc.fit(X)}
\end{Highlighting}
\end{Shaded}

More info: \href{https://github.com/ChongYou/subspace-clustering}{github.com}

\hypertarget{soft-assignment-clustering}{%
\subsection{Soft-assignment Clustering}\label{soft-assignment-clustering}}

Soft clustering assigns to each point the probabilities of belonging to
each of the clusters instead of assigning it to only one cluster. This
gives you a measure on how certain the algorithm is about the clustering
of a point.

\hypertarget{gaussian-mixture-models}{%
\subsubsection{Gaussian Mixture Models}\label{gaussian-mixture-models}}

Gaussian mixture models try to find an ensemble of gaussian
distributions that best describe your data. These
distributions/components are used as your clusters. Your points belong
to each cluster with a certain probability. To find these distributions,
we use an \emph{expectation maximization} algorithm:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Assume the centers of your Gaussians (e.g.~by k-means) and calculate
  for each point the probability of being generated by each
  distribution (\(p(x_i \in C_k | \phi_i, \mu_k, \sigma_k)\)).
\item
  Change the parameters to maximize the likelihood of the data, given
  the cluster probabilities for all points.
\end{enumerate}

The probability of a data point belonging to a cluster can be calculated
via Bayes theorem.

More info on the theory:
\href{https://brilliant.org/wiki/gaussian-mixture-model/}{brilliant.org}.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.mixture }\ImportTok{import}\NormalTok{ GaussianMixture}
\NormalTok{gm }\OperatorTok{=}\NormalTok{ GaussianMixture(n\_components}\OperatorTok{=}\DecValTok{4}\NormalTok{, covariance\_type}\OperatorTok{=}\StringTok{\textquotesingle{}full\textquotesingle{}}\NormalTok{)}
\NormalTok{gm.fit(X)}
\NormalTok{gm.predict\_proba(X)}
\end{Highlighting}
\end{Shaded}

More info:
\href{https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html}{scikit-learn.org}

\hypertarget{other-models}{%
\subsubsection{Other models}\label{other-models}}

Other models also have means to calculate cluster probabilities for points.
For the HDBSCAN-algorithm see \href{https://hdbscan.readthedocs.io/en/latest/soft_clustering.html}{here}.

\hypertarget{artificial-neural-networks-for-clustering}{%
\subsection{Artificial Neural Networks for Clustering}\label{artificial-neural-networks-for-clustering}}

See chapter \emph{Neural Networks}
(\protect\hyperlink{Neuralux5cux2520Networks}{5})

\hypertarget{mapping-to-lower-dimensions}{%
\section{Mapping to lower dimensions}\label{mapping-to-lower-dimensions}}

\hypertarget{manifold-learning}{%
\subsection{Manifold learning}\label{manifold-learning}}

\hypertarget{isomap}{%
\subsubsection{Isomap}\label{isomap}}

\hypertarget{local-linear-embedding}{%
\subsubsection{Local linear embedding}\label{local-linear-embedding}}

\hypertarget{multi-dimensional-scaling}{%
\subsubsection{Multi dimensional scaling}\label{multi-dimensional-scaling}}

\hypertarget{decomposition-techniques}{%
\subsection{Decomposition techniques}\label{decomposition-techniques}}

\hypertarget{SVD2}{%
\subsubsection{Singular value decomposition}\label{SVD2}}

Singular value decomposition is used to compress large matrices of your
data into smaller ones, with much less data, but without loosing a lot
of information. Please visit the \protect\hyperlink{SVD1}{mathematical explanation} for
the underlying mechanisms.\\

\hypertarget{principle-component-analysis-pca}{%
\subsubsection{Principle Component analysis (PCA)}\label{principle-component-analysis-pca}}

MAke subchapter: Kernel PCA

\hypertarget{outlier-detection}{%
\section{Outlier detection}\label{outlier-detection}}

\hypertarget{local-outlier-factor}{%
\subsection{Local outlier factor}\label{local-outlier-factor}}

\hypertarget{isolation-forest}{%
\subsection{Isolation forest}\label{isolation-forest}}

\hypertarget{generative-models}{%
\chapter{Generative models}\label{generative-models}}

\hypertarget{generative-models-for-discrete-data}{%
\section{Generative Models for Discrete Data}\label{generative-models-for-discrete-data}}

\hypertarget{bayesian-concept-learning}{%
\subsection{Bayesian Concept Learning}\label{bayesian-concept-learning}}

can learn a concept \(c \in C\) from positive examples alone. For that
define the posterior: \(p(c|\mathcal{D})\). To get to learn a concept you
need a hypothesis space \(\mathcal{H}\) and a version space (a subset of
\(\mathcal{H}\)) that is consistent with \(\mathcal{D}\). You choose a
hypothesis \(h\) by assuming that samples are randomly chosen from the
true concept and calculate
\(p(\mathcal{D}|h)=\lbrack \frac{1}{|h|}\rbrack^N\) (sampling the \(N\) data
points from \(h\)). You than choose the hypothesis that has the highest
probability (thereby you choose suspicious coincidences of too broad
models). The priors can be chosen e.g.~by giving lower priority to
concepts with complex rules (e.g.~"all powers of 2 below 100 but not
64."). This is subjective, however often beneficial for rapid
learning.\\
Using Bayes rule, we can calculate the posterior:
\[p(h|\mathcal{D}) =\dfrac{p(\mathcal{D}|h)p(h)}{p(\mathcal{D})} =  \dfrac{p(\mathcal{D}|h)p(h)}{\sum_{h' \in \mathcal{H}}p(\mathcal{D}|h')p(h')}=\dfrac{\mathbb{I}(\mathcal{D} \in h)p(h)}{\sum_{h' \in \mathcal{H}}\mathbb{I}(\mathcal{D} \in h')p(h')},\]
where \(\mathbb{I}(\mathcal{D} \in h)p(h)\) = 1 if the data adhere to the
\(h\). The maximum of \(p(h|\mathcal{D})\) is the \textbf{MAP estimate}.

With more data the MAP-estimate converges to the MLE. If the true
hypothesis is in \(\mathcal{H}\) then MLE and MAP will converge to it
(\(\rightarrow\) consistent estimators).~If you take the entire
distribution of the hypotheses you get a distribution for the estimate
(and not a point prediction) \(\rightarrow\) \textbf{posterior predictive
distribution}.
\[p(\tilde{x}|\mathcal{D}) = \sum_h p(\tilde{x}|h)p(h|\mathcal{D})\]
This weighting of hypotheses is called \textbf{Bayes model averaging}. For
small data sets you get a vague posterior and broad predictive
distribution. You can replace the posteriors with their delta-function:
\[p(\tilde{x}|\mathcal{D}) = \sum_h p(\tilde{x}|h)\delta_{\hat{h}_{\text{MAP}}}(h)\]
\(\rightarrow\) \textbf{plug-in approximation} (under-represents uncertainty).

\hypertarget{beta-binomial-model}{%
\subsection{Beta-binomial model}\label{beta-binomial-model}}

This is a distribution that uses a binomial distribution as its
likelihood and a beta-distribution over it's \(\theta\) parameter as its
prior.

\hypertarget{likelihood}{%
\subsubsection{Likelihood}\label{likelihood}}

\[p(\mathcal{D}|\theta) = \text{Bin}(k|n, \theta) \propto \theta^k (1-\theta)^{n-k},\]
where \(k\) are the successful trials, \(n\) are the total trials and
\(\theta\) are the success-probabilities of the single experiments. \(k\)
and \(n-k\) are \emph{sufficient statistics of the data}:
\(p(\theta|\mathcal{D} = p(\theta|k, n-k))\).

\hypertarget{prior}{%
\subsubsection{Prior}\label{prior}}

\[\text{Beta}(\theta|\alpha, \beta) \propto \theta^{\alpha-1}(1-\theta)^{\beta-1}\]
the parameters \(\alpha\) and \(\beta\) are used as hyper parameters. The
prior has the same form as the likelihood \(\rightarrow\) \emph{conjugate
prior}.

\hypertarget{posterior}{%
\subsubsection{Posterior}\label{posterior}}

\[p(\theta|\mathcal{D}) \propto \text{Bin}(k|n,\theta)\text{Beta}(\theta|\alpha, \beta)=\text{Beta}(\theta|k+\alpha,n-k+\beta)\]
We add pseudo-counts (\(\alpha, \beta\)) to empirical counts (\(N, k\)). The
posterior predictive distribution is: \[\begin{aligned}
                p(\tilde{x}=1|\mathcal{D})& =\int_0^1 p(\tilde{x}=1|\theta)p(\theta|\mathcal{D})\mathrm{d}\theta 
                        =\int_0^1 \theta\text{Beta}(\theta|N-k+\alpha,k+\beta)\mathrm{d}\theta \\
                        & =\text{E}[\theta|\mathcal{D}]=\dfrac{N-k+\alpha}{N\cancel{-k+k}+\alpha+\beta} \\
            \end{aligned}\] If instead we used the MLE for \(\theta\)
instead (\(p(\theta|\mathcal{D}) = p(\theta|\theta_{\text{MLE}})\)) and we
only had little data and no failures (e.g.~3 coin flips and all are
tails). Then the MLE estimate would be \(\theta_{\text{MLE}}) = 0/3 = 0\).
This is called \emph{zero count estimate} problem or \emph{black swan paradox}
(i.e.~you don't attribute possibilities to something you have never seen
before). Solution: You use a uniform prior (\(\alpha = \beta = 1\)):
\(p(\tilde{x}=1|\mathcal{D}) = \dfrac{N-k+1}{N+2}\).

\hypertarget{dirichlet-multinomial-model}{%
\subsection{Dirichlet-multinomial model}\label{dirichlet-multinomial-model}}

Before: model of \(k\) , now: \(k\) times a (e.g.~four pips on a die roll)
in \(n\) experiments.

\hypertarget{prior-1}{%
\subsubsection{Prior:}\label{prior-1}}

The Dirichlet distribution:
\[\text{Dir}(\theta|\alpha) = \dfrac{1}{B({\alpha})}\prod\limits_{k=1}^K \theta_k^{\alpha_k-1}\]

\hypertarget{posterior-1}{%
\subsubsection{Posterior:}\label{posterior-1}}

\[\begin{aligned}
            p({\theta}|\mathcal{D})& \propto p(\mathcal{D}|{\theta})p({\theta|\alpha}) \\
                & \propto \prod\limits_{k=1}^K\theta_k^{N_k}\theta_k^{\alpha_k-1} = \prod\limits_{k=1}^K\theta_k^{N_k+\alpha_k-1}\\
                & =\text{Dir}({\theta}|\alpha_1+N_1,\cdots,\alpha_K+N_K)
            \end{aligned}\] The posterior predictive distribution is:
\[\begin{aligned}
                p(\tilde{\tilde{X}}=j|\mathcal{D})& =\int p(\tilde{X}=j|{\theta})p({\theta}|\mathcal{D})\mathrm{d}{\theta} \\
                    & =\int p(\tilde{X}=j|\theta_j)\left[\int p({\theta}_{-j}, \theta_j|\mathcal{D})\mathrm{d}{\theta}_{-j}\right]\mathrm{d}\theta_j \\
                    & =\int \theta_jp(\theta_j|\mathcal{D})\mathrm{d}\theta_j=\text{E}[\theta_j|\mathcal{D}]=\dfrac{N_j+\alpha_j}{\sum_k N_k+\alpha_k}
                \end{aligned}\] (Again, we avoid the the zero-count
problem via the pseudo counts.)

\hypertarget{regression}{%
\chapter{Regression}\label{regression}}

\hypertarget{evaluation-of-regression-models}{%
\section{Evaluation of regression models}\label{evaluation-of-regression-models}}

\hypertarget{r2-score}{%
\subsection{R\^{}2 score}\label{r2-score}}

\hypertarget{mean-squared-error}{%
\subsection{Mean squared error}\label{mean-squared-error}}

\hypertarget{visual-tools}{%
\subsection{Visual tools}\label{visual-tools}}

\hypertarget{linear-models}{%
\section{Linear Models}\label{linear-models}}

\hypertarget{ordinary-least-squares}{%
\subsection{Ordinary Least Squares}\label{ordinary-least-squares}}

\hypertarget{lasso-regression}{%
\subsection{Lasso regression}\label{lasso-regression}}

\hypertarget{ridge-regression}{%
\subsection{Ridge regression}\label{ridge-regression}}

\hypertarget{kernel-ridge-regression}{%
\subsubsection{Kernel ridge regression}\label{kernel-ridge-regression}}

\hypertarget{bayesian-regression}{%
\subsection{Bayesian regression}\label{bayesian-regression}}

\hypertarget{generalized-linear-models}{%
\subsection{Generalized linear models}\label{generalized-linear-models}}

\hypertarget{gaussian-process-regression}{%
\section{Gaussian process regression}\label{gaussian-process-regression}}

Gaussian process regression is based on Bayesian Probability: You
generate many models and calculate the probability of your models given
the samples. You make predictions based on the probabilities of your
models.

You get non-linear functions to your data by using non-linear kernels:
You assume that input data points that are similar, will have similar
target values. The concept of similarity (e.g.~same hour of the day) is
encoded in the kernels that you use.

\begin{figure}
\centering
\includegraphics{figures/Gaussian_Process_Regression.png}
\caption{Schema of the training process of Gaussian process regression. The
left graph shows the prior samples of functions before. These functions
are then conditioned on the data (graph in middle). The right graph
shows the predictions with the credible intervals in gray. \emph{Source:
\href{https://commons.wikimedia.org/wiki/File:Gaussian_Process_Regression.png}{user Cdipaolo96 on
wikimedia.org}
.}}
\end{figure}

\textbf{Pros:}

\begin{itemize}
\item
  The model reports the predictions with a certain probability.
\item
\end{itemize}

\textbf{Cons:}

\begin{itemize}
\item
  Training scales with \(O(n^3)\).
\item
  You need to design or choose a kernel.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.gaussian\_process }\ImportTok{import}\NormalTok{ GaussianProcessRegressor}
\ImportTok{from}\NormalTok{ sklearn.gaussian\_process.kernels }\ImportTok{import}\NormalTok{ DotProduct, WhiteKernel, RBF, ExpSineSquared}
\NormalTok{kernel }\OperatorTok{=}\NormalTok{ DotProduct() }\OperatorTok{+}\NormalTok{ WhiteKernel() }\OperatorTok{+}\NormalTok{ RBF() }\OperatorTok{+}\NormalTok{ ExpSineSquared() }\CommentTok{\# The kernel hyperparameters are tuned by the model}
\NormalTok{gpr }\OperatorTok{=}\NormalTok{ GaussianProcessRegressor(kernel}\OperatorTok{=}\NormalTok{kernel)}
\NormalTok{gpr.fit(X, y)}
\NormalTok{gpr.predict(X, return\_std}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

More info:
\href{https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html}{scikit-learn.org}\\

\hypertarget{gradient-boosted-tree-regression}{%
\section{Gradient boosted tree regression}\label{gradient-boosted-tree-regression}}

Apart from classification, gradient boosted trees also allow for
regression. It works like gradient boosted trees for classification: You
iteratively add decision tree regressors that minimize the regression
loss of the already fitted ensemble. A \href{https://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html}{decision tree
regressor}
is a decision tree that is trained on continuous data instead of
discrete classification data, but its \href{https://medium.com/analytics-vidhya/regression-trees-decision-tree-for-regression-machine-learning-e4d7525d8047}{output is still
discrete}.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.ensemble }\ImportTok{import}\NormalTok{ GradientBoostingRegressor}
\NormalTok{gbr }\OperatorTok{=}\NormalTok{ GradientBoostingRegressor(n\_estimators }\OperatorTok{=} \DecValTok{500}\NormalTok{, min\_samples\_split }\OperatorTok{=}\DecValTok{5}\NormalTok{, max\_depth }\OperatorTok{=} \DecValTok{4}\NormalTok{, max\_features}\OperatorTok{=}\StringTok{"sqrt"}\NormalTok{, n\_iter\_no\_change}\OperatorTok{=}\DecValTok{15}\NormalTok{)}
\NormalTok{gbr.fit(X, y)}
\end{Highlighting}
\end{Shaded}

More info:
\href{https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html}{scikit-learn.org}\\

\hypertarget{time-series-forecasting}{%
\section{Time Series Forecasting}\label{time-series-forecasting}}

For ``normal'' settings the order of the samples does not play a role (e.g.~blood sugar level of one sample is independent of the others). In time series however, the samples need to be represented in an ordered vector or matrix (e.g.~The temperature of Jan 2nd is not independent of the temperature on Jan 1st).

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\NormalTok{df }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{"data.csv"}\NormalTok{, header}\OperatorTok{=}\DecValTok{0}\NormalTok{, index\_col}\OperatorTok{=}\DecValTok{0}\NormalTok{, names}\OperatorTok{=}\NormalTok{[}\StringTok{"date"}\NormalTok{, }\StringTok{"sales"}\NormalTok{])}
\NormalTok{sales\_series }\OperatorTok{=}\NormalTok{ df[}\StringTok{"sales"}\NormalTok{] }\CommentTok{\# pandas series make working with time series easier }
\end{Highlighting}
\end{Shaded}

\hypertarget{arimax-model}{%
\subsection{ARIMA(X) Model}\label{arimax-model}}

univariate time series model with exogenous regressor.

\hypertarget{varmmax-model}{%
\subsection{VARMMA(X) Model}\label{varmmax-model}}

Multivariate time series model, where the variables can influence each other and the target can influence the variables and vice versa.

\hypertarget{prophet-model}{%
\subsection{Prophet-Model}\label{prophet-model}}

Explain Prophet model from Facebook.
Source: \url{https://otexts.com/fpp3/prophet.html}

\hypertarget{neural-networks-neural-networks}{%
\chapter{Neural Networks \{\#Neural Networks\}}\label{neural-networks-neural-networks}}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

On the most basic level neural networks consist of many simple models
(e.g.~linear and logistic models) that are chained together in a
directed network. The models sit on the neurons (nodes) of the network.
The most important components of neurons are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Activation}: \(a = Wx+b\) (\(W\) = weights and \(b\) = bias)
\item
  \textbf{Non-linearity}: \(f(x, \theta)=\sigma(a)\) (e.g.~a sigmoid function
  for logistic regression, giving you a probability output. \(\theta\)
  is a threshold)
\end{enumerate}

The neurons (nodes) in the first layer uses as its input the sample
values and feeds its output into the activation function of the next
nodes in the next layer, a.s.o. The later layers should thereby learn
more and more complicated concepts or structures.

\centering

\begin{figure}
\hypertarget{CDF}{%
\centering
\includegraphics[width=0.7\textwidth,height=\textheight]{./figures/Artificial_Neural_Network.jpg}
\caption{Model of an artificial neural network with one hidden layer. \emph{Figure
from \href{https://commons.wikimedia.org/wiki/File:Artificial_Neural_Network.jpg}{user LearnDataSci on
wikimedia.org}.}}\label{CDF}
}
\end{figure}

\hypertarget{non-linearities}{%
\subsection{Non-Linearities}\label{non-linearities}}

Different non-linear functions can be used to generate the output of the
neurons.

\hypertarget{sigmoidlogistic-functions}{%
\subsubsection{Sigmoid/Logistic Functions}\label{sigmoidlogistic-functions}}

\hypertarget{tanh-functions}{%
\subsubsection{Tanh Functions}\label{tanh-functions}}

\hypertarget{rectifiersrelu}{%
\subsubsection{Rectifiers/ReLU}\label{rectifiersrelu}}

\hypertarget{terminology-1}{%
\subsubsection{Terminology}\label{terminology-1}}

\begin{itemize}
\item
  \textbf{Input layer/visible layer:} Input variables
\item
  \textbf{Hidden layer:} Layers of nodes between input and output layer
\item
  \textbf{Output layer:} Layer of nodes that produce output variables
\item
  \textbf{Size:} Number of nodes in the network
\item
  \textbf{Width:} Number of nodes in a layer
\item
  \textbf{Depth:} Number of layers
\item
  \textbf{Capacity:} The type of functions that can be learned by the
  network
\item
  \textbf{Architecture:} The arrangement of layers and nodes in the network
\end{itemize}

\hypertarget{feedforward-neural-network-multi-layer-perceptron}{%
\section{Feedforward Neural Network / Multi-Layer Perceptron}\label{feedforward-neural-network-multi-layer-perceptron}}

This is the simplest type of proper neural networks. Each neuron of a
layer is connected to each neuron of the next layer and there are no
cycles. The outputs of the previous layer corresponds to the \(x\) in the
activation function. Each output (\(x_i\)) of the previous layer gets it's
own weight (\(w_i\)) in each node and a bias (\(b\)) is added to each node.
Neurons with a very high output are ``active'' neurons, those with
negative outputs are ``inactive''. The result is mapped to the probability
range by (commonly) a sigmoid function. The output is then again given
to the next layer.\\
If your input layer has 6400 features (80*80 image), a network with 2
hidden layers of 16 nodes will have
\(6400*16+16*16+16*10+16+16+10 = 102'858\) parameters. This is a very high
number of degrees of freedom and requires a lot of training samples.

\begin{verbatim}
        from torch import nn

        class CustomNet(nn.Module):
            def __init__(self):
                super(CustomNet, self).__init__()
                self.lin_layer_1 = nn.Linear(in_features=10, out_features=10)
                self.relu = nn.ReLU()
                self.lin_layer_2 = nn.Linear(in_features=10, out_features=10)

            def forward(self, x):
                x = self.lin_layer_1(x)
                x = self.relu
                x = self.lin_layer_2(x)
                return x

            def num_flat_features(self, x):
                size = x.size()[1:] # Use all but the batch dimension
                num = 1
                for i in size:
                    num *= i
                return num

        new_net = CustomNet()
\end{verbatim}

\hypertarget{bekpropageshn}{%
\subsection{Bekpropageshn}\label{bekpropageshn}}

This is the method by which neural networks learn the optimal weights
and biases of the nodes. The components are a cost function and a
gradient descent method.\\
The cost function analyses the difference between the designated
activation in the output layer (according to the label of the data) and
the actual activation of that layer. Commonly a residual sum of squares
is used.\\
You get the direction of the next best parameter-combination by using a
\emph{stochastic gradient descent} algorithm using the gradient for your cost
function:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  We use a ``mini-batch'' of images for each round/step of the gradient
  descent.
\item
  We calculate squared residual of each feature of the output layer
  for each sample.
\item
  From that we calculate what the bias or weights from the output
  layer and the activation from the last hidden layer must have been
  to get this result. We average that out for all images in our
  mini-batch.
\item
  From that we calculate the weights, biases and activations of the
  upstream layers \(\rightarrow\) we \emph{backpropagate}.
\end{enumerate}

\hypertarget{convolutional-neural-networks}{%
\section{Convolutional Neural Networks}\label{convolutional-neural-networks}}

\hypertarget{autoencoders}{%
\section{Autoencoders}\label{autoencoders}}

Contrary to the other architectures, autoencoders are used for
unsupervised learning. Their goal is to compress and decompress data to
learn the most important structures of the data. The layers therefore
become smaller for the encoding step and the later layers get bigger
again, up to the original representation of the data. The optimization
problem is now:
\[\min_{W,b} \frac{1}{N}*\sum_{i=1}^N ||x_i - \hat{x}_i||^2\] with \(x_i\)
being the original datapoint and \(\hat{x}_i\) the reconstructed
datapoint.

\centering

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth,height=\textheight]{./figures/Autoencoder_schema.png}
\caption{Model of an autoencoder. The encoder layers compress the data towards
the code layer, the decoder layers decompress the data again. \emph{Figure
from \href{https://commons.wikimedia.org/wiki/File:Autoencoder_schema.png}{Michela Massi on
wikimedia.org}.}}
\end{figure}

\hypertarget{autoencoders-for-clustering}{%
\subsection{Autoencoders for clustering}\label{autoencoders-for-clustering}}

You can look at layers of a NN as ways to represent data in different
form of complexity and compactness. The code layers of autoencoders are
a very compact way to represent the data. You can then use the
compressed representation of the code layer and do clustering on that
data. Because the code layer is however not optimized for that task XXXX
combined the cost function of the \textbf{autoencoder and k-means
clustering}:
\[\min_{W,b} \frac{1}{N}*\sum_{i=1}^N ||x_i - \hat{x}_i||^2 - \lambda \sum_{i=1}^N ||f(x_i) - c_i||^2\]
with \(f(x_i)\) being the non-linearity of the code layer and \(\lambda\) is
a weight constant.\\
XXXX adapted spectral clustering (section
\protect\hyperlink{Spectralux5cux2520Clustering}{3.3}) using autoencoders by replacing the
(linear) eigen-decomposition with the (non-linear) decomposition by the
encoder. As in spectral clustering the Laplacian matrix is used as the
the input to the decomposition step (encoder) and the compressed
representation (code-layer) is fed into k-means clustering.\\
\textbf{Deep subspace clustering} by XXXX employs autoencoders combined with
sparse subspace clustering \protect\hyperlink{SSP}{3.3.1}. They used autoencoders and optimized for a compact
representation of the code layer: \[\begin{split}
                \min_{W,b} \frac{1}{N}*\sum_{i=1}^N ||x_i - \hat{x}_i||^2 - \lambda ||V||_1 \\
                \text{s.t.} F(X) = F(X)*V \text{ and diag}(V)=0
            \end{split}\] with V being the sparse representation of the
code layer (\(F(X)\)) .

\hypertarget{generative-adversarial-networks}{%
\section{Generative Adversarial Networks}\label{generative-adversarial-networks}}

\hypertarget{recurrent-neural-networks}{%
\section{Recurrent Neural Networks}\label{recurrent-neural-networks}}

\hypertarget{explanation-and-inspection-methods}{%
\chapter{Explanation and inspection methods}\label{explanation-and-inspection-methods}}

  \bibliography{references.bib}

\end{document}
